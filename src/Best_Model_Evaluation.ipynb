{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0d4f38",
   "metadata": {},
   "source": [
    "## Regression Analysis on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19530cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Dwyer\n",
    "\"\"\"\n",
    "\n",
    "# set TF GPU memory growth so that it doesn't hog everything at once\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from optuna_train import *\n",
    "debug_mode = True  # faster experiments for debugging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "print(pd.__path__)\n",
    "assert pd.__path__[0]!='/opt/anaconda/lib/python3.8/site-packages/pandas', 'Error! You are using deprecated python packages outside your conda environment. Did you use Jupyter Lab again?' \n",
    "# this is a nefarious problem with current version of anaconda, root cause is conda version install your own local one!\n",
    "# lightly more superficial root cause is that you sometimes use jupyter lab which triggers you to use the /opt/anaconda/bin path backup when it sees jupyter lab isn't in local environment which breaks everything (uses outdated pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCs_only = False # turn on to only look at BCs!!\n",
    "\n",
    "#Prepare the DataFrame that will be used downstream\n",
    "dp = DataPreparer(fn='../datasets/chrest_course_sample.csv') # TODO: change me!\n",
    "df = dp.getDataframe()\n",
    "\n",
    "########################################\n",
    "### Look for biggest Species Values! ###\n",
    "mean_vals = df.filter(like='Yi').mean()\n",
    "sort_idx = np.argsort(mean_vals)\n",
    "mean_vals = mean_vals[sort_idx][::-1]\n",
    "plt.bar(mean_vals.index, mean_vals)\n",
    "plt.title('Mean Values of Species in Dataset')\n",
    "plt.xticks(rotation=90, ha=\"right\")\n",
    "plt.show()\n",
    "display(mean_vals[:10])\n",
    "important_species = list(mean_vals[:10].index)\n",
    "print(important_species)\n",
    "########################################\n",
    "\n",
    "if BCs_only:\n",
    "    #df = df.sample(2)\n",
    "    df=pd.concat([df.iloc[:1], df.iloc[-1:]],axis=0) # select boundary conditions!\n",
    "    df.index=range(len(df))\n",
    "    dp.df = df\n",
    "\n",
    "# currently passing dp eventually we want to abstract all the constants into 1 class\n",
    "dm = DataManager(df, dp)\n",
    "dm.train_portion=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eca734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" prepare PCDNNV2 for loading (from prior experiments) \"\"\"\n",
    "\n",
    "exprExec = PCDNNV2ExperimentExecutor()\n",
    "exprExec.debug_mode = debug_mode\n",
    "exprExec.setModelFactory(PCDNNV2ModelFactory())\n",
    "exprExec.use_dynamic_pred=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1925e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_analyzer.model_analysis as model_analysis\n",
    "import importlib; importlib.reload(model_analysis)\n",
    "\n",
    "bestModel, experimentSettings = exprExec.modelFactory.openBestModel()\n",
    "emb_and_regressor = bestModel = bestModel.get_layer('emb_and_regression_model')\n",
    "print(experimentSettings.keys())\n",
    "print(experimentSettings['dataSetMethod'])\n",
    "#dm.createTrainTestData(experimentSettings['dataSetMethod'], experimentSettings['noOfCpv'], experimentSettings['ipscaler'], experimentSettings['opscaler'])\n",
    "dm = experimentSettings['data_manager']\n",
    "\n",
    "print(f'\\nexperimentSettings: {str(experimentSettings)[:300]}...')\n",
    "print(f'\\nbestModel.input_shape: {bestModel.input_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21419a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpler than reconstructing, but sanity is good...\n",
    "linear_embedder = bestModel.get_layer('linear_embedding')\n",
    "regressor = bestModel.get_layer('regressor')\n",
    "\n",
    "print(bestModel.input_shape)\n",
    "print(bestModel.output_shape)\n",
    "tf.keras.utils.plot_model(bestModel, expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1fec4",
   "metadata": {},
   "source": [
    "## Manually Construct Data & Prepare Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ef224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, zmix_train, zmix_test = dm.getTrainTestData()\n",
    "source_train, source_test = dm.getSourceTrainTestData()\n",
    "\n",
    "if BCs_only: # This is a hack to plot regression analysis for just the boundary cases\n",
    "    X_test, Y_test, zmix_test, source_test = dm.getAllData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPV_train = linear_embedder({\"species_input\": np.asarray(X_train)})\n",
    "true_dyn_train = linear_embedder({\"species_input\": np.asarray(source_train)})\n",
    "true_dyn_test = linear_embedder({\"species_input\": np.asarray(source_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict_train = {\"species_input\": X_train, 'zmix': zmix_train}\n",
    "input_dict_test = {\"species_input\": X_test, 'zmix': zmix_test}\n",
    "output_dict_train = {'static_source_prediction': Y_train, 'dynamic_source_prediction': true_dyn_train}\n",
    "output_dict_test = {'static_source_prediction': Y_test, 'dynamic_source_prediction': true_dyn_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e231721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import pcdnnv2_model_factory\n",
    "\n",
    "@tf.function\n",
    "def R2(yt,yp): return tf.reduce_mean(1-tf.reduce_mean((yp-yt)**2, axis=0)/tf.math.reduce_variance(yt,axis=0))\n",
    "\n",
    "# for metric definitions see get_metric_dict()\n",
    "metrics={'static_source_prediction': R2, 'dynamic_source_prediction': R2}\n",
    "emb_and_regressor.compile(loss=None, optimizer='adam', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143bde9",
   "metadata": {},
   "source": [
    "# Best Model Evaluation:\n",
    "## R^2 Eval -- \n",
    "(**NOTE: requires max batch size or you get erroneous results!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified to make \"raw evaluation\" (7/27/22) (as long as batch size is entire dataset!)\n",
    "eval_func = lambda input_dict, output_dict: emb_and_regressor.evaluate(input_dict, output_dict, \n",
    "                                                                       batch_size=input_dict['species_input'].shape[0],\n",
    "                                                                       return_dict=True, verbose=False)\n",
    "\n",
    "eval_ = eval_func(input_dict_test, output_dict_test)\n",
    "print(eval_)\n",
    "\n",
    "print(f'Total loss: {eval_[\"loss\"]}')\n",
    "print(f'CPV_source_prediction R^2: {eval_[\"dynamic_source_prediction_R2\"]}')\n",
    "print(f'Static_deps_prediction R^2: {eval_[\"static_source_prediction_R2\"]}')\n",
    "print(f'Average R^2: {(eval_[\"dynamic_source_prediction_R2\"]+eval_[\"static_source_prediction_R2\"])/2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c16e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentSettings.keys()\n",
    "experimentSettings['val_losses']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057437f",
   "metadata": {},
   "source": [
    "## QQ regression plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# QQ plots are good!!\n",
    "#all_dependants = [\"souener\", \"souspecO2\", \"souspecCO\", \"souspecCO2\", \"souspecH2O\", \"souspecOH\", \"souspecH2\", \"souspecCH4\"]\n",
    "all_dependants = [\"souener\"] + dm.input_data_cols\n",
    "print(dm.input_data_cols)\n",
    "def make_Error_plots(input_dict, output_dict, name, plot_residuals=False, names=None):\n",
    "    preds = emb_and_regressor.predict(input_dict)\n",
    "    if names is None: names = list(range(preds[name].shape[1]))\n",
    "    \n",
    "    residuals = output_dict[name]-preds[name]\n",
    "    print('mae', np.mean(np.abs(residuals)))\n",
    "    Y_vals = residuals if plot_residuals else preds[name]\n",
    "    plt_name = 'Residual' if plot_residuals else 'Q-Q'\n",
    "    \n",
    "    for i in range(preds[name].shape[1]):\n",
    "        plt.figure(i)\n",
    "        plt.plot(output_dict[name][:, i], Y_vals[:,i], '.')\n",
    "        plt.title(f'{plt_name} Plot {name}-{names[i]}')\n",
    "        plt.show()\n",
    "    return residuals\n",
    "make_Error_plots(input_dict_test, output_dict_test, 'static_source_prediction', names=all_dependants, plot_residuals=False)\n",
    "make_Error_plots(input_dict_test, output_dict_test, 'dynamic_source_prediction', plot_residuals=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587bce4",
   "metadata": {},
   "source": [
    "## Compare Boundary Conditions Predictions to Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BCs_only:\n",
    "    preds = emb_and_regressor.predict(input_dict_test)\n",
    "    preds = pd.DataFrame(dm.outputScaler.inverse_transform(preds['static_source_prediction'])[:,1:], columns=dm.input_data_cols)\n",
    "    targets = pd.DataFrame(dm.outputScaler.inverse_transform(output_dict_test['static_source_prediction'])[:,1:], columns=dm.input_data_cols)\n",
    "    preds = preds[important_species]\n",
    "    targets = targets[important_species]\n",
    "\n",
    "    print('test inputs: ')\n",
    "    display(input_dict_test)\n",
    "    print('targets: ')\n",
    "    display(targets)\n",
    "    print('preds: ')\n",
    "    display(preds)\n",
    "\n",
    "    plt.bar(preds.columns, preds.iloc[0])\n",
    "    plt.xticks(rotation=90, ha=\"right\")\n",
    "    plt.title('Predictions')\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(preds.columns, targets.iloc[0])\n",
    "    plt.xticks(rotation=90, ha=\"right\")\n",
    "    plt.title('Targets')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86602d6",
   "metadata": {},
   "source": [
    "## Residual Regression Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a48072",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Error_plots(input_dict_test, output_dict_test, 'static_source_prediction', names=all_dependants, plot_residuals=True)\n",
    "make_Error_plots(input_dict_test, output_dict_test, 'dynamic_source_prediction', plot_residuals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3622a73",
   "metadata": {},
   "source": [
    "### CPV Distribution Plots (its Weird!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CPV_train.shape[1]):\n",
    "    plt.figure(i)\n",
    "    plt.hist(CPV_train[:,i].numpy().squeeze())\n",
    "    plt.title(f'CPV-{i} hist')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ac3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on names!\n",
    "def sanity_check_names(): # function to prevent namespace pollution\n",
    "    input_dict_train, input_dict_test, output_dict_train, output_dict_test = exprExec.prepare_model_data_dicts(dm=dm)\n",
    "    X_train_cols = dm.df_testing[dm.input_data_cols].columns\n",
    "    source_train_cols = source_train.columns\n",
    "\n",
    "    # check that order of source-terms matches order of species\n",
    "    assert all(np.array([col[2:] for col in X_train_cols]) == np.array([col[7:] for col in source_train_cols]))\n",
    "sanity_check_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
