{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH4-AIR Notebook \n",
    "This notebook contains all the methods and the 2 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression#, sRidge\n",
    "from sklearn import gaussian_process\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import scipy.optimize\n",
    "from sklearn.utils.optimize import _check_optimize_result\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, WhiteKernel, RationalQuadratic, ExpSineSquared\n",
    "import time\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "# demonstrate data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data into a dataframe\n",
    "df = pd.read_csv('NewData_flames_data_with_L1_L2_errors_CH4-AIR_without_trimming.txt')\n",
    "df = df.iloc[:-1]\n",
    "\n",
    "#create an integer representation of the flame-id and add to the data frame\n",
    "df['flame_key_int'] = df[' flame_key'].mul(10000000).astype(int)\n",
    "\n",
    "#create an integer to determine if the flame is included by the framework in the manifold creation and reverselookup\n",
    "#framework_untrimmed_flameids = [0.00115982, 0.00122087, 0.00128512, 0.00135276, 0.00142396, 0.0014989, 0.00157779, 0.00166083, 0.00174825, 0.00184026, 0.00193711, 0.00203907, 0.00214639, 0.00225936, 0.00237827, 0.01]\n",
    "\n",
    "framework_untrimmed_flameids = ['2.0276547153583627E-4', '2.1343733845877503E-4', '2.2467088258818426E-4', '2.3649566588229923E-4', '2.4894280619189394E-4', '2.6204505914936203E-4', '2.7583690436774953E-4', '2.903546361765785E-4', '3.056364591332405E-4', '3.2172258856130585E-4', '3.3865535638032194E-4', '0.0032353354497370902']\n",
    "\n",
    "\n",
    "framework_untrimmed_flame_key_ints = [int(float(framework_untrimmed_flameids[i])*10000000) for i in range(len(framework_untrimmed_flameids))]\n",
    "\n",
    "def isFlame_included(flame_key_int):\n",
    "    if flame_key_int in framework_untrimmed_flame_key_ints:\n",
    "        ret_val = 1\n",
    "    else:\n",
    "        ret_val = 0\n",
    "    return ret_val\n",
    "\n",
    "df['is_flame_included_by_framework'] = df['flame_key_int'].map(lambda x: isFlame_included(x))\n",
    "\n",
    "df['souener_deciles'] = pd.qcut(df['souener'],10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PCAs using all the data and add to DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_principal_components = 5\n",
    "\n",
    "pca = PCA(n_components=num_principal_components)\n",
    "\n",
    "icovariates = []\n",
    "for c in df.columns:\n",
    "    if c[0:2] == 'Yi':\n",
    "        icovariates.append(c)\n",
    "\n",
    "X = df[icovariates].values\n",
    "        \n",
    "pure_pca_dim_cols = [\"PURE_PCA_\"+str(i+1) for i in range(num_principal_components)]\n",
    "\n",
    "pca.fit_transform(X)\n",
    "        \n",
    "df_pure_pca = pd.DataFrame(pca.transform(X), columns = pure_pca_dim_cols)\n",
    "        \n",
    "df = pd.concat([df,df_pure_pca], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sparse PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsepca = SparsePCA(n_components=num_principal_components)\n",
    "      \n",
    "sparse_pca_dim_cols = [\"SPARSE_PCA_\"+str(i+1) for i in range(num_principal_components)]\n",
    "\n",
    "sparsepca.fit_transform(X)\n",
    "        \n",
    "df_sparse_pca = pd.DataFrame(sparsepca.transform(X), columns = sparse_pca_dim_cols)\n",
    "        \n",
    "df = pd.concat([df,df_sparse_pca], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PCAs orthogonal to Zmix and add to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmix_pca_dim_cols = [\"Zmix_PCA_\"+str(i+1) for i in range(num_principal_components)]\n",
    "\n",
    "#these are the weights calculated on the basis of molar weight of Hydrogen\n",
    "wopt = np.array([0.25131806468584, 1.0, 0.0, 0.0, 0.05926499970012948, 0.11189834407236524, 0.03053739933116691, 0.05926499970012948, 0.0, 0.07742283372149472, 0.14371856860332313, 0.14371856860332313, 0.20112514400193687, 1.0, 0.0, 0.0, 0.03473494419333629, 0.06713785861443991, 0.09743596683886535, 0.09743596683886535, 0.12582790137651187, 0.04027033873046593, 0.07742283372149472, 0.11180607885607882, 0.14371856860332313, 0.17341738612784788, 0.20112514400193687, 0.024566681794273966, 0.04795526192839207, 0.04795526192839207, 0.0, 0.06713048065088474, 0.12581494366075874, 0.17755300484072126, 0.034730994502665966, 0.0, 0.0, 0.0, 0.03249947443158002, 0.0, 0.0372961080230628, 0.07191024382448291, 0.024564706019978535, 0.023426986426879046, 0.023426986426879046, 0.023426986426879046, 0.0, 0.16374935944566987, 0.18286442054789118, 0.07024850027715426, 0.09152158240065958, 0.0, 0.0] , dtype=float)\n",
    "\n",
    "'''\n",
    "Zmix = wopt * Xi --> Zmix += mixFracMassCoeff[s] * Yi[s] in the following code and then it is normalized\n",
    "Z_f = 0.25131806468584\n",
    "Z_ox = 0.0\n",
    "(Zmix - Z_ox) / (Z_f - Z_ox)\n",
    "\n",
    "public double calc(double[] Yi) {\n",
    "\t\tdouble Zmix = 0.;\n",
    "\t\tfor (int s = 0; s < species.length; s++) {\n",
    "\t\t\tZmix += mixFracMassCoeff[s] * Yi[s];\n",
    "\t\t}\n",
    "\t\treturn (Zmix - Z_ox) / (Z_f - Z_ox);\n",
    "\t}\n",
    "'''\n",
    "\n",
    "# DD is this creating Zmix PCA data?\n",
    "w = wopt[:,np.newaxis]\n",
    "\n",
    "# center the data\n",
    "Xcenter = X - np.mean(X)\n",
    "\n",
    "A = np.cov(X.T)\n",
    "\n",
    "# calculate A - ww^TA\n",
    "L = A - np.dot(np.dot(w,w.T),A)\n",
    "\n",
    "# get the first eigen vector\n",
    "values,vectors = np.linalg.eig(L)\n",
    "\n",
    "vectors = np.real(vectors)\n",
    "\n",
    "values = np.real(values)\n",
    "\n",
    "df_zmix_pca = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "To reproduce Zmix the actual formula should be \n",
    "\n",
    "df_zmix_pca[zmix_pca_dim_cols[0]] = X.dot(wopt)/0.25131806468584\n",
    "\n",
    "instead of\n",
    "\n",
    "df_zmix_pca[zmix_pca_dim_cols[0]] = Xcenter.dot(wopt)\n",
    "'''\n",
    "\n",
    "df_zmix_pca[zmix_pca_dim_cols[0]] = X.dot(wopt)/0.25131806468584\n",
    "\n",
    "for i in range(len(zmix_pca_dim_cols)-1):\n",
    "    df_zmix_pca[zmix_pca_dim_cols[i+1]] = Xcenter.dot(vectors.T[i])\n",
    "        \n",
    "df = pd.concat([df,df_zmix_pca], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPARSE_PCA_1</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>1.253314e-17</td>\n",
       "      <td>0.286373</td>\n",
       "      <td>-0.750042</td>\n",
       "      <td>-0.194973</td>\n",
       "      <td>0.150304</td>\n",
       "      <td>0.233717</td>\n",
       "      <td>0.233740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPARSE_PCA_2</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-9.183768e-19</td>\n",
       "      <td>0.225447</td>\n",
       "      <td>-0.129779</td>\n",
       "      <td>-0.129172</td>\n",
       "      <td>-0.119761</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.842094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPARSE_PCA_3</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>2.322953e-17</td>\n",
       "      <td>0.123754</td>\n",
       "      <td>-0.219574</td>\n",
       "      <td>-0.104949</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.099932</td>\n",
       "      <td>0.256069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPARSE_PCA_4</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>1.577447e-17</td>\n",
       "      <td>0.104093</td>\n",
       "      <td>-0.141999</td>\n",
       "      <td>-0.092147</td>\n",
       "      <td>-0.016238</td>\n",
       "      <td>0.080892</td>\n",
       "      <td>0.231227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPARSE_PCA_5</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-1.134465e-17</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>-0.142216</td>\n",
       "      <td>-0.041498</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.107378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count          mean       std       min       25%       50%  \\\n",
       "SPARSE_PCA_1  16441.0  1.253314e-17  0.286373 -0.750042 -0.194973  0.150304   \n",
       "SPARSE_PCA_2  16441.0 -9.183768e-19  0.225447 -0.129779 -0.129172 -0.119761   \n",
       "SPARSE_PCA_3  16441.0  2.322953e-17  0.123754 -0.219574 -0.104949  0.005794   \n",
       "SPARSE_PCA_4  16441.0  1.577447e-17  0.104093 -0.141999 -0.092147 -0.016238   \n",
       "SPARSE_PCA_5  16441.0 -1.134465e-17  0.063366 -0.142216 -0.041498  0.009792   \n",
       "\n",
       "                   75%       max  \n",
       "SPARSE_PCA_1  0.233717  0.233740  \n",
       "SPARSE_PCA_2  0.014580  0.842094  \n",
       "SPARSE_PCA_3  0.099932  0.256069  \n",
       "SPARSE_PCA_4  0.080892  0.231227  \n",
       "SPARSE_PCA_5  0.048427  0.107378  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[sparse_pca_dim_cols].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PURE_PCA_1</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-1.491012e-17</td>\n",
       "      <td>0.325190</td>\n",
       "      <td>-0.490615</td>\n",
       "      <td>-0.237739</td>\n",
       "      <td>-0.114940</td>\n",
       "      <td>0.235481</td>\n",
       "      <td>0.791990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURE_PCA_2</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-5.726350e-18</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>-0.317691</td>\n",
       "      <td>-0.189716</td>\n",
       "      <td>-0.046028</td>\n",
       "      <td>0.133318</td>\n",
       "      <td>0.784541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURE_PCA_3</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>1.111506e-17</td>\n",
       "      <td>0.060418</td>\n",
       "      <td>-0.151627</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.035349</td>\n",
       "      <td>0.181628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURE_PCA_4</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-2.519459e-17</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>-0.041384</td>\n",
       "      <td>-0.011442</td>\n",
       "      <td>-0.001986</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.058253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PURE_PCA_5</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>2.346588e-18</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>-0.008928</td>\n",
       "      <td>-0.000457</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>0.028629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean       std       min       25%       50%  \\\n",
       "PURE_PCA_1  16441.0 -1.491012e-17  0.325190 -0.490615 -0.237739 -0.114940   \n",
       "PURE_PCA_2  16441.0 -5.726350e-18  0.238648 -0.317691 -0.189716 -0.046028   \n",
       "PURE_PCA_3  16441.0  1.111506e-17  0.060418 -0.151627 -0.025262  0.003245   \n",
       "PURE_PCA_4  16441.0 -2.519459e-17  0.017964 -0.041384 -0.011442 -0.001986   \n",
       "PURE_PCA_5  16441.0  2.346588e-18  0.012195 -0.026775 -0.008928 -0.000457   \n",
       "\n",
       "                 75%       max  \n",
       "PURE_PCA_1  0.235481  0.791990  \n",
       "PURE_PCA_2  0.133318  0.784541  \n",
       "PURE_PCA_3  0.035349  0.181628  \n",
       "PURE_PCA_4  0.007267  0.058253  \n",
       "PURE_PCA_5  0.008280  0.028629  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pure_pca_dim_cols].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zmix_PCA_1</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.212689</td>\n",
       "      <td>0.396438</td>\n",
       "      <td>0.631653</td>\n",
       "      <td>0.995403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zmix_PCA_2</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.309534</td>\n",
       "      <td>-0.386990</td>\n",
       "      <td>-0.153405</td>\n",
       "      <td>-0.041851</td>\n",
       "      <td>0.295016</td>\n",
       "      <td>0.831136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zmix_PCA_3</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>0.047216</td>\n",
       "      <td>0.238313</td>\n",
       "      <td>-0.740641</td>\n",
       "      <td>-0.083428</td>\n",
       "      <td>0.093586</td>\n",
       "      <td>0.235941</td>\n",
       "      <td>0.362813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zmix_PCA_4</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>0.077550</td>\n",
       "      <td>0.059719</td>\n",
       "      <td>-0.072796</td>\n",
       "      <td>0.052931</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>0.112476</td>\n",
       "      <td>0.256761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zmix_PCA_5</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>-0.081258</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>-0.139513</td>\n",
       "      <td>-0.088497</td>\n",
       "      <td>-0.079301</td>\n",
       "      <td>-0.069828</td>\n",
       "      <td>-0.039887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std       min       25%       50%  \\\n",
       "Zmix_PCA_1  16441.0  0.430075  0.260355  0.004543  0.212689  0.396438   \n",
       "Zmix_PCA_2  16441.0  0.072066  0.309534 -0.386990 -0.153405 -0.041851   \n",
       "Zmix_PCA_3  16441.0  0.047216  0.238313 -0.740641 -0.083428  0.093586   \n",
       "Zmix_PCA_4  16441.0  0.077550  0.059719 -0.072796  0.052931  0.080623   \n",
       "Zmix_PCA_5  16441.0 -0.081258  0.017962 -0.139513 -0.088497 -0.079301   \n",
       "\n",
       "                 75%       max  \n",
       "Zmix_PCA_1  0.631653  0.995403  \n",
       "Zmix_PCA_2  0.295016  0.831136  \n",
       "Zmix_PCA_3  0.235941  0.362813  \n",
       "Zmix_PCA_4  0.112476  0.256761  \n",
       "Zmix_PCA_5 -0.069828 -0.039887  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[zmix_pca_dim_cols].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zmix</th>\n",
       "      <td>16441.0</td>\n",
       "      <td>0.430075</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.212689</td>\n",
       "      <td>0.396438</td>\n",
       "      <td>0.631653</td>\n",
       "      <td>0.995403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean       std       min       25%       50%       75%  \\\n",
       "Zmix  16441.0  0.430075  0.260355  0.004543  0.212689  0.396438  0.631653   \n",
       "\n",
       "           max  \n",
       "Zmix  0.995403  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Zmix']].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the 'X' matrix column arrangement for the Constrained PCA formulation\n",
    "#icovariates\n",
    "#[CH4, H, O, O2, OH, H2O, HO2, H2O2, C, CH, CH2, CH2(S), CH3, H2, CO, CO2, HCO, CH2O, CH2OH, CH3O, CH3OH, C2H, C2H2, C2H3, C2H4, C2H5, C2H6, HCCO, CH2CO, HCCOH, N, NH, NH2, NH3, NNH, NO, NO2, N2O, HNO, CN, HCN, H2CN, HCNN, HCNO, HOCN, HNCO, NCO, C3H7, C3H8, CH2CHO, CH3CHO, N2, AR]\n",
    "#df.head()['Zmix']\n",
    "#X[3].dot(wopt)/0.25131806468584\n",
    "#Zmix matches with the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\nimport numpy as np\\nimport sklearn\\n\\ndates=['April-10', 'April-11', 'April-12', 'April-13']\\nfruits=['Apple', 'Papaya', 'Banana', 'Mango']\\nprices=[3, 1, 2, 4]\\n\\n\\n\\ntdf = pd.DataFrame({'Date':dates ,\\n                   'Fruit':fruits ,\\n                   'Price': prices})\\n\\nprint('Before')\\nprint(tdf)\\n\\ntdf_shuffled=sklearn.utils.shuffle(tdf,random_state=0)\\nprint(tdf_shuffled)\\nprint('After')\\nprint(tdf)\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "dates=['April-10', 'April-11', 'April-12', 'April-13']\n",
    "fruits=['Apple', 'Papaya', 'Banana', 'Mango']\n",
    "prices=[3, 1, 2, 4]\n",
    "\n",
    "\n",
    "\n",
    "tdf = pd.DataFrame({'Date':dates ,\n",
    "                   'Fruit':fruits ,\n",
    "                   'Price': prices})\n",
    "\n",
    "print('Before')\n",
    "print(tdf)\n",
    "\n",
    "tdf_shuffled=sklearn.utils.shuffle(tdf,random_state=0)\n",
    "print(tdf_shuffled)\n",
    "print('After')\n",
    "print(tdf)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_included_flames_int = df[df['is_flame_included_by_framework'] == 1]['flame_key_int'].unique()\n",
    "\n",
    "framework_excluded_flames_int = df[df['is_flame_included_by_framework'] == 0]['flame_key_int'].unique()\n",
    "\n",
    "all_flames_int = df['flame_key_int'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, df_totalData):\n",
    "        self.df = df_totalData\n",
    "        self.outputScaler = None\n",
    "        self.inputScaler = None\n",
    "        self.zmixScaler = None\n",
    "        self.df_training = None\n",
    "        self.df_testing = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.X_scaled_train = None\n",
    "        self.X_scaled_test = None\n",
    "        self.rom_train = None\n",
    "        self.rom_test = None\n",
    "        self.rom_scaled_train = None\n",
    "        self.rom_scaled_test = None\n",
    "        self.zmix_train = None\n",
    "        self.zmix_test = None\n",
    "        self.zmix_scaled_train = None\n",
    "        self.zmix_scaled_test = None\n",
    "        self.Y_train = None\n",
    "        self.Y_test = None\n",
    "        self.Y_scaled_train = None\n",
    "        self.Y_scaled_test = None\n",
    "        \n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def train_test_split_on_flamekey(df, train_portion=0.5, seed=0):\n",
    "        import random\n",
    "        random.seed(seed)\n",
    "        flame_keys = list(set(df['flame_key_int']))\n",
    "        random.shuffle(flame_keys)\n",
    "        train_set_keys = flame_keys[:int(len(flame_keys)*train_portion)]\n",
    "        test_set_keys = flame_keys[int(len(flame_keys)*train_portion):]\n",
    "        print('train_set_keys: ', train_set_keys)\n",
    "        print('test_set_keys: ', test_set_keys)\n",
    "\n",
    "        train_set = df[np.isin(df['flame_key_int'], train_set_keys)]\n",
    "        test_set = df[np.isin(df['flame_key_int'], test_set_keys)]\n",
    "        print('train: ', train_set['flame_key_int'].unique()[:5])\n",
    "        print('test: ', test_set['flame_key_int'].unique()[:5])\n",
    "        return train_set, test_set\n",
    "    \n",
    "    def _createTrainTestDfs(self, method):\n",
    "        if method=='randomequalflamesplit':\n",
    "            train_set, test_set = self.train_test_split_on_flamekey(df)\n",
    "        if(method == \"randomequaltraintestsplit\"):\n",
    "            df_shuffled = shuffle(self.df, random_state=0)\n",
    "            self.df_training = df_shuffled[::2]\n",
    "            self.df_testing = df_shuffled[1::2]\n",
    "        else:\n",
    "            training_flames_int = []\n",
    "            testing_flames_int = []\n",
    "\n",
    "            if(method == \"frameworkincludedexcludedequalsplit\"):\n",
    "\n",
    "                # why are there 4 of these loops??\n",
    "                for x in framework_included_flames_int:\n",
    "                    training_flames_int.append(x)\n",
    "\n",
    "                for x in framework_excluded_flames_int[::2]:\n",
    "                    training_flames_int.append(x)\n",
    "\n",
    "                for x in framework_included_flames_int:\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "                for x in framework_excluded_flames_int[1::2]:\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "            elif(method == \"frameworkincludedtrainexcludedtest\"):\n",
    "                for x in framework_included_flames_int:\n",
    "                    training_flames_int.append(x)\n",
    "\n",
    "                for x in framework_excluded_flames_int:\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "            elif(method == \"frameworkincludedtrainexcludedandincludedtest\"):\n",
    "                for x in framework_included_flames_int:\n",
    "                    training_flames_int.append(x)\n",
    "\n",
    "                for x in framework_included_flames_int:\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "                for x in framework_excluded_flames_int:\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "            else:\n",
    "                for x in all_flames_int:\n",
    "                    training_flames_int.append(x)\n",
    "                    testing_flames_int.append(x)\n",
    "\n",
    "            self.df_training = self.df[self.df['flame_key_int'].isin(training_flames_int)]\n",
    "\n",
    "            self.df_testing = self.df[self.df['flame_key_int'].isin(testing_flames_int)]\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def _createTrainTestData(self,method,numCpvComponents):\n",
    "\n",
    "        method_parts = method.split('_')\n",
    "\n",
    "        self._createTrainTestDfs(method_parts[1])\n",
    "\n",
    "        input_data_cols = []\n",
    "        \n",
    "        rom_cols = []\n",
    "        \n",
    "        output_data_cols = [\"souener\"]        \n",
    "\n",
    "        if method_parts[0] == \"ZmixCpv\":\n",
    "            input_data_cols = [\"Zmix\",\"Cpv\"]\n",
    "        elif method_parts[0] == \"ZmixPCA\":\n",
    "            input_data_cols = zmix_pca_dim_cols[0:numCpvComponents] \n",
    "        elif method_parts[0] == \"SparsePCA\":\n",
    "            input_data_cols = sparse_pca_dim_cols[0:numCpvComponents]\n",
    "        elif method_parts[0] == \"PurePCA\":\n",
    "            input_data_cols = pure_pca_dim_cols[0:numCpvComponents]\n",
    "        elif method_parts[0] == \"ZmixAndSparsePCA\":\n",
    "            input_data_cols = ['Zmix'] + sparse_pca_dim_cols[0:numCpvComponents]\n",
    "        elif method_parts[0] == \"ZmixAndPurePCA\":\n",
    "            input_data_cols = ['Zmix'] + pure_pca_dim_cols[0:numCpvComponents]    \n",
    "        elif method_parts[0] == \"ZmixAllSpecies\":    \n",
    "            input_data_cols = ['Zmix'] + icovariates\n",
    "        elif method_parts[0] == \"AllSpeciesZmixCpv\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = [\"Cpv\"]\n",
    "        elif method_parts[0] == \"AllSpeciesZmixPCA\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = zmix_pca_dim_cols[0:numCpvComponents]            \n",
    "        elif method_parts[0] == \"AllSpeciesPurePCA\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = pure_pca_dim_cols[0:numCpvComponents]\n",
    "        elif method_parts[0] == \"AllSpeciesZmixAndPurePCA\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = pure_pca_dim_cols[0:numCpvComponents]            \n",
    "        elif method_parts[0] == \"AllSpeciesSparsePCA\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = sparse_pca_dim_cols[0:numCpvComponents]\n",
    "        elif method_parts[0] == \"AllSpeciesZmixAndSparsePCA\":\n",
    "            input_data_cols = icovariates\n",
    "            rom_cols = sparse_pca_dim_cols[0:numCpvComponents]             \n",
    "        else:\n",
    "            input_data_cols = icovariates\n",
    "\n",
    "        self.X_train = self.df_training [input_data_cols].values\n",
    "        self.X_test = self.df_testing [input_data_cols].values\n",
    "        self.rom_train = self.df_training [rom_cols].values\n",
    "        self.rom_test = self.df_testing [rom_cols].values\n",
    "        self.zmix_train = self.df_training ['Zmix'].values\n",
    "        self.zmix_test = self.df_testing ['Zmix'].values\n",
    "        self.Y_train = self.df_training [output_data_cols].values\n",
    "        self.Y_test = self.df_testing [output_data_cols].values\n",
    "        print(\"In _createTrainTestData Y_test.shape: \" + str(self.Y_test.shape))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def _setInputOutputScalers(self, ipscaler, opscaler):\n",
    "        if ipscaler == \"MinMaxScaler\":\n",
    "            self.inputScaler = MinMaxScaler()\n",
    "            self.zmixScaler = MinMaxScaler()\n",
    "        elif ipscaler == \"QuantileTransformer\":\n",
    "            self.inputScaler = QuantileTransformer()\n",
    "            self.zmixScaler = QuantileTransformer()\n",
    "        else:\n",
    "            self.inputScaler = None\n",
    "            self.zmixScaler = None\n",
    "        if opscaler == \"MinMaxScaler\":\n",
    "            self.outputScaler = MinMaxScaler()\n",
    "            self.romScaler = MinMaxScaler()\n",
    "        elif opscaler == \"QuantileTransformer\":\n",
    "            self.outputScaler = QuantileTransformer()\n",
    "            self.romScaler = QuantileTransformer()\n",
    "        else:\n",
    "            self.outputScaler = None\n",
    "            self.romScaler = None\n",
    "            \n",
    "    def createTrainTestData(self,dataSetMethod,numCpvComponents, ipscaler, opscaler):\n",
    "        self._createTrainTestData(dataSetMethod,numCpvComponents)\n",
    "        \n",
    "        self._setInputOutputScalers(ipscaler, opscaler)\n",
    "        \n",
    "        if self.inputScaler is not None:\n",
    "            self.X_scaled_train = self.inputScaler.fit_transform(self.X_train)\n",
    "            self.X_scaled_test = self.inputScaler.fit_transform(self.X_test)\n",
    "            \n",
    "            self.zmix_scaled_train = self.zmixScaler.fit_transform(self.zmix_train.reshape(self.zmix_train.shape[0], 1))\n",
    "            self.zmix_scaled_test = self.zmixScaler.fit_transform(self.zmix_test.reshape(self.zmix_test.shape[0], 1))\n",
    "            self.zmix_train = self.zmix_train.flatten()\n",
    "            self.zmix_scaled_train = self.zmix_scaled_train.flatten()\n",
    "            self.zmix_test = self.zmix_test.flatten()\n",
    "            self.zmix_scaled_test = self.zmix_scaled_test.flatten()\n",
    "            \n",
    "        else:\n",
    "            self.X_scaled_train = None\n",
    "            self.X_scaled_test = None\n",
    "            self.zmix_scaled_train = None\n",
    "            self.zmix_scaled_test = None\n",
    "            \n",
    "            \n",
    "        if self.outputScaler is not None:\n",
    "            self.Y_scaled_train = self.outputScaler.fit_transform(self.Y_train.reshape(self.Y_train.shape[0], 1))\n",
    "            self.Y_scaled_test = self.outputScaler.fit_transform(self.Y_test.reshape(self.Y_test.shape[0], 1))\n",
    "            self.Y_train = self.Y_train.flatten()\n",
    "            self.Y_scaled_train = self.Y_scaled_train.flatten()\n",
    "            self.Y_test = self.Y_test.flatten()\n",
    "            self.Y_scaled_test = self.Y_scaled_test.flatten()\n",
    "            if not self.rom_train.shape[1] == 0:\n",
    "                self.rom_scaled_train = self.romScaler.fit_transform(self.rom_train)\n",
    "                self.rom_scaled_test = self.romScaler.fit_transform(self.rom_test)\n",
    "        else:\n",
    "            self.Y_scaled_train = None\n",
    "            self.Y_scaled_test = None\n",
    "            self.rom_scaled_train = None\n",
    "            self.rom_scaled_test = None\n",
    "        print(\"In createTrainTestData Y_test.shape: \" + str(self.Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGPR(GaussianProcessRegressor):\n",
    "    def __init__(self, *args, max_iter=150,max_fun=50, gtol=1e-05, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._max_iter = max_iter\n",
    "        self._gtol = gtol\n",
    "        self._max_fun = max_fun\n",
    "\n",
    "    #ftol = 1000000000000.0 (factr) * np.finfo(float).eps --> 0.0002220446049250313\n",
    "    #,'ftol':0.0000002220446049250313\n",
    "    def _constrained_optimization(self, obj_func, initial_theta, bounds):\n",
    "        if self.optimizer == \"fmin_l_bfgs_b\":\n",
    "            opt_res = scipy.optimize.minimize(obj_func, initial_theta, method=\"L-BFGS-B\", jac=True, bounds=bounds, options={'maxiter':self._max_iter,'maxfun':self._max_fun,'gtol': self._gtol})\n",
    "            _check_optimize_result(\"lbfgs\", opt_res)\n",
    "            theta_opt, func_min = opt_res.x, opt_res.fun\n",
    "        elif callable(self.optimizer):\n",
    "            theta_opt, func_min = self.optimizer(obj_func, initial_theta, bounds=bounds)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown optimizer %s.\" % self.optimizer)\n",
    "        return theta_opt, func_min\n",
    "\n",
    "\n",
    "\n",
    "def getGPModel(kernel=\"Matern\"):\n",
    "    if kernel == \"Matern_RationalQuadratic\":\n",
    "\n",
    "        # medium term irregularities\n",
    "        k1 = 0.5* Matern(length_scale=2, nu=3/2)\n",
    "        k2 = 0.5* RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "\n",
    "        '''\n",
    "        k4 = 0.1**2 * RBF(length_scale=0.1) \\+ WhiteKernel(noise_level=0.1**2,\n",
    "                      noise_level_bounds=(1e-3, np.inf))  # noise terms\n",
    "        '''\n",
    "        kernel = k1 + k2\n",
    "\n",
    "    elif kernel == \"RationalQuadratic\":\n",
    "\n",
    "        # medium term irregularities\n",
    "        kernel = RationalQuadratic(length_scale=1.0, alpha=1.0)    \n",
    "\n",
    "    else:\n",
    "        kernel = Matern(length_scale=2, nu=3/2)\n",
    "\n",
    "    return CustomGPR(kernel=kernel) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nexperimentTrackingFields = [\\'Model\\',\\'Dataset\\',\\'Cpv Type\\',\\'#Cpv\\',\"ZmixExists\",\\'MAE\\',\\'TAE\\',\\'MSE\\',\\'TSE\\',\\'#Pts\\',\\'FitTime\\',\\'PredTime\\']\\n\\ndf_experimentTracker = pd.DataFrame(columns=experimentTrackingFields)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "experimentTrackingFields = ['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime']\n",
    "\n",
    "df_experimentTracker = pd.DataFrame(columns=experimentTrackingFields)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os#must import this library\\n\\nif os.path.exists(\\'results.csv\\'):\\n        os.remove(\\'results.csv\\') #this deletes the file\\nelse:\\n        print(\"The results.csv file does not exist\")\\n\\nresultsFile = open(\\'results.csv\\', \\'w\\')\\n\\nprintStr = \"\\t\"\\n\\nprintStr = printStr.join(experimentTrackingFields)\\n\\n\\nresultsFile.write(printStr)\\n\\nresultsFile.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os#must import this library\n",
    "\n",
    "if os.path.exists('results.csv'):\n",
    "        os.remove('results.csv') #this deletes the file\n",
    "else:\n",
    "        print(\"The results.csv file does not exist\")\n",
    "\n",
    "resultsFile = open('results.csv', 'w')\n",
    "\n",
    "printStr = \"\\t\"\n",
    "\n",
    "printStr = printStr.join(experimentTrackingFields)\n",
    "\n",
    "\n",
    "resultsFile.write(printStr)\n",
    "\n",
    "resultsFile.write(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentExecutor:\n",
    "    def __init__(self):\n",
    "        self.dm = None\n",
    "        self.modelType = None\n",
    "        self.model = None\n",
    "        self.df_experimentTracker = None\n",
    "        self.fit_time = None\n",
    "        self.pred_time = None\n",
    "        self.err = None\n",
    "     \n",
    "    def setModel(self,model):\n",
    "        self.model = model\n",
    "\n",
    "    def executeExperiment(self, dataManager, modelType, dataType=\"randomequaltraintestsplit\",inputType=\"ZmixPCA\",noOfCpv=5):\n",
    "        self.dm = dataManager\n",
    "        \n",
    "        self.modelType = modelType\n",
    "        \n",
    "        dataSetMethod = inputType + '_' + dataType\n",
    "        \n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "        \n",
    "        self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test)\n",
    "        \n",
    "        if inputType.find('Zmix') != -1:\n",
    "            ZmixPresent = 'Y'\n",
    "        else:\n",
    "            ZmixPresent = 'N'\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.err[2]),str(self.err[0]),str(self.err[3]),str(self.err[1]),str(self.err[5]),str(self.fit_time),str(self.pred_time)]\n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.err[2])\n",
    "\n",
    "        print(printStr)\n",
    "        \n",
    "    def executeExperiments(self,dataManager, modelType, df_experimentTracker):\n",
    "        self.dm = dataManager\n",
    "        self.modelType = modelType\n",
    "        self.df_experimentTracker = df_experimentTracker\n",
    "        \n",
    "        #Experiments  \n",
    "        \n",
    "        dataTypes = [\"randomequaltraintestsplit\",\"frameworkincludedtrainexcludedtest\"]\n",
    "        #dataTypes = [\"frameworkincludedtrainexcludedtest\"]\n",
    "        \n",
    "        #inputTypes = [\"ZmixCpv\",\"ZmixPCA\",\"SparsePCA\",\"PurePCA\",\"ZmixAndPurePCA\",\"ZmixAndSparsePCA\",\"ZmixAllSpecies\",\"AllSpecies\"]\n",
    "        inputTypes = [\"ZmixAndPurePCA\",\"ZmixAndSparsePCA\"]\n",
    "        #inputTypes = [\"ZmixCpv\"]\n",
    "        \n",
    "        for dataType in dataTypes:\n",
    "            \n",
    "            for inputType in inputTypes:\n",
    "                #ZmixCpv_randomequaltraintestsplit\n",
    "                dataSetMethod = inputType + '_' + dataType\n",
    "                        \n",
    "                if inputType.find('Zmix') != -1:\n",
    "                    ZmixPresent = 'Y'\n",
    "                else:\n",
    "                    ZmixPresent = 'N'\n",
    "                    \n",
    "                if inputType.find('PCA') != -1:\n",
    "                    \n",
    "                    noOfCpvs = [item for item in range(1, 6)]\n",
    "                    \n",
    "                    for noOfCpv in noOfCpvs:\n",
    "                        #                           dataSetMethod,noOfCpvs, ipscaler, opscaler\n",
    "                        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "                        \n",
    "                        self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test)\n",
    "                                                \n",
    "                        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.err[2]),str(self.err[0]),str(self.err[3]),str(self.err[1]),str(self.err[5]),str(self.fit_time),str(self.pred_time)]\n",
    "\n",
    "                        self.df_experimentTracker.loc[len(self.df_experimentTracker)] = experimentResults        \n",
    "\n",
    "                        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.err[2])\n",
    "\n",
    "                        print(printStr)\n",
    "\n",
    "                        printStr = \"\\t\"\n",
    "\n",
    "                        printStr = printStr.join(experimentResults)\n",
    "\n",
    "                        resultsFile.write(printStr)\n",
    "\n",
    "                        resultsFile.write(\"\\n\")\n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                   \n",
    "                    if inputType.find('ZmixCpv') != -1:\n",
    "                        noOfCpv = 1\n",
    "                    else:\n",
    "                        noOfCpv = 53\n",
    "                        \n",
    "                    #                           dataSetMethod,noOfCpvs, ipscaler, opscaler\n",
    "                    self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "\n",
    "                    self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test)    \n",
    "\n",
    "                    experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.err[2]),str(self.err[0]),str(self.err[3]),str(self.err[1]),str(self.err[5]),str(self.fit_time),str(self.pred_time)]\n",
    "                        \n",
    "                    self.df_experimentTracker.loc[len(self.df_experimentTracker)] = experimentResults        \n",
    "\n",
    "                    printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.err[2])\n",
    "\n",
    "                    print(printStr)\n",
    "\n",
    "                    printStr = \"\\t\"\n",
    "\n",
    "                    printStr = printStr.join(experimentResults)\n",
    "\n",
    "                    resultsFile.write(printStr)\n",
    "\n",
    "                    resultsFile.write(\"\\n\")\n",
    "        \n",
    "    def computeError (self, Y_pred, Y_test):\n",
    "        evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "        evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "\n",
    "        evaluation_df_1['souener_pred_L2'] = evaluation_df_1['souener_pred_L1'] * evaluation_df_1['souener_pred_L1']\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1Percent'] = ((evaluation_df_1['souener'] - evaluation_df_1['souener_pred'])/evaluation_df_1['souener']) \n",
    "\n",
    "        TotalAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()\n",
    "\n",
    "        TotalSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()\n",
    "\n",
    "        MeanAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()/evaluation_df_1['souener_pred_L1'].abs().count()\n",
    "\n",
    "        MeanSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()/evaluation_df_1['souener_pred_L2'].abs().count()\n",
    "\n",
    "        NumPoints = evaluation_df_1['souener_pred_L1Percent'].abs().count()\n",
    "\n",
    "        MeanPercentageError = evaluation_df_1['souener_pred_L1Percent'].abs().sum()/NumPoints\n",
    "\n",
    "        return [TotalAbsoluteError,TotalSquaredError,MeanAbsoluteError,MeanSquaredError,MeanPercentageError,NumPoints]\n",
    "\n",
    "            \n",
    "    def printError (self,err):\n",
    "        TotalAbsoluteError = err[0]\n",
    "\n",
    "        TotalSquaredError = err[1]\n",
    "\n",
    "        MeanAbsoluteError = err[2]\n",
    "\n",
    "        MeanSquaredError = err[3]\n",
    "\n",
    "        MeanPercentageError = err[4]\n",
    "\n",
    "        NumPoints = err[5]\n",
    "        \n",
    "        print ('Total Absolute Error: ', TotalAbsoluteError)\n",
    "        print ('Mean Absolute Error: ', MeanAbsoluteError)\n",
    "        print ('Mean Percentage Error: ', MeanPercentageError)\n",
    "        print ('Total Squared Error: ', TotalSquaredError)\n",
    "        print ('Mean Squared Error: ', MeanSquaredError)\n",
    "        print ('Number of Points: ', NumPoints)\n",
    "\n",
    "    def computeAndPrintError(self,Y_pred, Y_test):    \n",
    "        self.err = computeError (Y_pred, Y_test)\n",
    "        printError (err)\n",
    "        logError(err)\n",
    "        return err    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitModelAndCalcErr(self,X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "        t = time.process_time()\n",
    "\n",
    "        self.model.fit(X_train, Y_train)\n",
    "\n",
    "        self.fit_time = time.process_time() - t\n",
    "\n",
    "        t = time.process_time()\n",
    "\n",
    "        Y_pred = self.model.predict(X_test, return_std=False)\n",
    "\n",
    "        self.pred_time = time.process_time() - t\n",
    "        \n",
    "        #computeAndPrintError(Y_pred, Y_test)\n",
    "\n",
    "        self.err = self.computeError (Y_pred, Y_test)\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = ExperimentExecutor()\\nexpExectr.setModel(getGPModel(\"Matern\"))\\nexpExectr.executeExperiment(dm, \"GP_Matern\", dataType=\"randomequaltraintestsplit\",inputType=\"ZmixPCA\",noOfCpv=5)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = ExperimentExecutor()\n",
    "expExectr.setModel(getGPModel(\"Matern\"))\n",
    "expExectr.executeExperiment(dm, \"GP_Matern\", dataType=\"randomequaltraintestsplit\",inputType=\"ZmixPCA\",noOfCpv=5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = ExperimentExecutor()\\nexpExectr.setModel(getGPModel(\"Matern\"))\\nexpExectr.executeExperiments(dm, \"GP_Matern\", df_experimentTracker)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = ExperimentExecutor()\n",
    "expExectr.setModel(getGPModel(\"Matern\"))\n",
    "expExectr.executeExperiments(dm, \"GP_Matern\", df_experimentTracker)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = ExperimentExecutor()\\nexpExectr.setModel(getGPModel(\"Matern_RationalQuadratic\"))\\nexpExectr.executeExperiments(dm, \"GP_Matern_RationalQuadratic\", df_experimentTracker)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = ExperimentExecutor()\n",
    "expExectr.setModel(getGPModel(\"Matern_RationalQuadratic\"))\n",
    "expExectr.executeExperiments(dm, \"GP_Matern_RationalQuadratic\", df_experimentTracker)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = ExperimentExecutor()\\nexpExectr.setModel(getGPModel(\"RationalQuadratic\"))\\nexpExectr.executeExperiments(dm, \"GP_RationalQuadratic\", df_experimentTracker)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = ExperimentExecutor()\n",
    "expExectr.setModel(getGPModel(\"RationalQuadratic\"))\n",
    "expExectr.executeExperiments(dm, \"GP_RationalQuadratic\", df_experimentTracker)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_experimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_experimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments.csv', sep='\\t',encoding='utf-8', index=False)\\n\\n#!!!!!!! Very Important !!!!!!\\nresultsFile.close()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_experimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments.csv', sep='\\t',encoding='utf-8', index=False)\n",
    "\n",
    "#!!!!!!! Very Important !!!!!!\n",
    "resultsFile.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple DNN Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResiduals(Y_test,Y_pred):\n",
    "    evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "    evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "    evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "    evaluation_df_1['res'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "   \n",
    "    return evaluation_df_1['res'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Souener]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndnnexperimentTrackingFields = [\\'Model\\',\\'Dataset\\',\\'Cpv Type\\',\\'#Cpv\\',\"ZmixExists\",\\'MAE\\',\\'TAE\\',\\'MSE\\',\\'TSE\\',\\'#Pts\\',\\'FitTime\\',\\'PredTime\\',\\'MAX-MAE\\',\\'MAX-TAE\\',\\'MAX-MSE\\',\\'MAX-TSE\\',\\'MIN-MAE\\',\\'MIN-TAE\\',\\'MIN-MSE\\',\\'MIN-TSE\\']\\n\\ndf_dnnexperimentTracker = pd.DataFrame(columns=dnnexperimentTrackingFields)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dnnexperimentTrackingFields = ['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "df_dnnexperimentTracker = pd.DataFrame(columns=dnnexperimentTrackingFields)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os#must import this library\\n\\nif os.path.exists(\\'results.csv\\'):\\n        os.remove(\\'results.csv\\') #this deletes the file\\nelse:\\n        print(\"The results.csv file does not exist\")\\n\\nresultsFile = open(\\'results.csv\\', \\'w\\')\\n\\nprintStr = \"\\t\"\\n\\nprintStr = printStr.join(dnnexperimentTrackingFields)\\n\\n\\nresultsFile.write(printStr)\\n\\nresultsFile.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os#must import this library\n",
    "\n",
    "if os.path.exists('results.csv'):\n",
    "        os.remove('results.csv') #this deletes the file\n",
    "else:\n",
    "        print(\"The results.csv file does not exist\")\n",
    "\n",
    "resultsFile = open('results.csv', 'w')\n",
    "\n",
    "printStr = \"\\t\"\n",
    "\n",
    "printStr = printStr.join(dnnexperimentTrackingFields)\n",
    "\n",
    "\n",
    "resultsFile.write(printStr)\n",
    "\n",
    "resultsFile.write(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=45)\n",
    "\n",
    "class DNNExperimentExecutor:\n",
    "    def __init__(self):\n",
    "        self.dm = None\n",
    "        self.modelType = None\n",
    "        self.model = None\n",
    "        self.df_experimentTracker = None\n",
    "        self.fit_time = None\n",
    "        self.pred_time = None\n",
    "        self.err = None\n",
    "        self.df_err = None \n",
    "        self.width = 512\n",
    "        self.halfwidth = 128    \n",
    "    \n",
    "    def setModel(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "\n",
    "\n",
    "    def build_and_compile_simple_dnn_model(self,noOfInputNeurons):\n",
    "        inputs = keras.Input(shape=(noOfInputNeurons,), name=\"inputs\")\n",
    "\n",
    "        x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "        \n",
    "        souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "        model = keras.Model(\n",
    "            inputs=[inputs],\n",
    "            outputs=[souener_pred],\n",
    "        )\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(loss='mean_absolute_error',optimizer=opt)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def executeExperiment(self, dataManager, modelType, dataType=\"randomequaltraintestsplit\", inputType=\"ZmixPCA\",noOfCpv=5):\n",
    "        self.dm = dataManager\n",
    "        \n",
    "        self.modelType = modelType\n",
    "        \n",
    "        dataSetMethod = inputType + '_' + dataType\n",
    "        \n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "        \n",
    "        self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test)\n",
    "        \n",
    "        if inputType.find('Zmix') != -1:\n",
    "            ZmixPresent = 'Y'\n",
    "        else:\n",
    "            ZmixPresent = 'N'\n",
    "\n",
    "                            #['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.df_err['MAE'].mean()),str(self.df_err['TAE'].mean()),str(self.df_err['MSE'].mean()),str(self.df_err['TSE'].mean()),str(self.df_err['#Pts'].mean()),str(self.fit_time),str(self.pred_time),str(self.df_err['MAE'].max()),str(self.df_err['TAE'].max()),str(self.df_err['MSE'].max()),str(self.df_err['TSE'].max()),str(self.df_err['MAE'].min()),str(self.df_err['TAE'].min()),str(self.df_err['MSE'].min()),str(self.df_err['TSE'].min())]\n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.err[2])\n",
    "\n",
    "        print(printStr)\n",
    "    \n",
    "    def executeSingleExperiment(self,noOfInputNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv):\n",
    "        \n",
    "        print('------------------ ' + 'executeSingleExperiments' + ' ------------------')\n",
    "        \n",
    "        #                           dataSetMethod,noOfCpvs, ipscaler, opscaler\n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "        \n",
    "        self.model = self.build_and_compile_simple_dnn_model(noOfInputNeurons)\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "        self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test)\n",
    "\n",
    "         #['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.df_err['MAE'].mean()),str(self.df_err['TAE'].mean()),str(self.df_err['MSE'].mean()),str(self.df_err['TSE'].mean()),str(self.df_err['#Pts'].mean()),str(self.fit_time),str(self.pred_time),str(self.df_err['MAE'].max()),str(self.df_err['TAE'].max()),str(self.df_err['MSE'].max()),str(self.df_err['TSE'].max()),str(self.df_err['MAE'].min()),str(self.df_err['TAE'].min()),str(self.df_err['MSE'].min()),str(self.df_err['TSE'].min())]\n",
    "\n",
    "        self.df_experimentTracker.loc[len(self.df_experimentTracker)] = experimentResults        \n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.df_err['MAE'].min())\n",
    "\n",
    "        print(printStr)\n",
    "\n",
    "        printStr = \"\\t\"\n",
    "\n",
    "        printStr = printStr.join(experimentResults)\n",
    "\n",
    "        resultsFile.write(printStr)\n",
    "\n",
    "        resultsFile.write(\"\\n\")\n",
    "\n",
    "    def executeExperiments(self,dataManager, modelType, df_experimentTracker):\n",
    "        self.dm = dataManager\n",
    "        self.modelType = modelType\n",
    "        self.df_experimentTracker = df_experimentTracker\n",
    "        \n",
    "        #Experiments  \n",
    "        \n",
    "        dataTypes = [\"randomequaltraintestsplit\",\"frameworkincludedtrainexcludedtest\"]\n",
    "        #dataTypes = [\"frameworkincludedtrainexcludedtest\"]\n",
    "        #dataTypes = [\"randomequaltraintestsplit\"]\n",
    "        \n",
    "        inputTypes = [\"ZmixCpv\",\"ZmixPCA\",\"SparsePCA\",\"PurePCA\",\"ZmixAndPurePCA\",\"ZmixAndSparsePCA\",\"ZmixAllSpecies\",\"AllSpecies\"]\n",
    "        #inputTypes = [\"ZmixAndPurePCA\",\"ZmixAndSparsePCA\"]\n",
    "        #inputTypes = [\"ZmixCpv\"]\n",
    "        #inputTypes = [\"PurePCA\"]\n",
    "        \n",
    "        for dataType in dataTypes:\n",
    "            print('=================== ' + dataType + ' ===================')\n",
    "            \n",
    "            for inputType in inputTypes:\n",
    "                \n",
    "                print('------------------ ' + inputType + ' ------------------')\n",
    "                    \n",
    "                #ZmixCpv_randomequaltraintestsplit\n",
    "                dataSetMethod = inputType + '_' + dataType\n",
    "                \n",
    "                noOfNeurons = 0\n",
    "                #ZmixAnd & ZmixAll\n",
    "                if inputType.find('ZmixA') != -1:\n",
    "                    noOfNeurons = noOfNeurons + 1\n",
    "\n",
    "                if inputType.find('Zmix') != -1:\n",
    "                    ZmixPresent = 'Y'\n",
    "                else:\n",
    "                    ZmixPresent = 'N'\n",
    "                    \n",
    "                if inputType.find('PCA') != -1:\n",
    "                    \n",
    "                    noOfCpvs = [item for item in range(1, 6)]\n",
    "                    \n",
    "                    for noOfCpv in noOfCpvs:\n",
    "                        noOfNeurons = noOfNeurons + 1                        \n",
    "                        self.executeSingleExperiment(noOfNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv)\n",
    "                else:\n",
    "\n",
    "                    if inputType.find('ZmixCpv') != -1:\n",
    "                        noOfCpv = 1\n",
    "                        noOfNeurons = 2\n",
    "                    else:\n",
    "                        noOfCpv = 53\n",
    "                        noOfNeurons = noOfNeurons + noOfCpv\n",
    "                    print('------------------ ' + str(noOfNeurons) + ' ------------------')\n",
    "                    self.executeSingleExperiment(noOfNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv)\n",
    "        \n",
    "    def computeError (self,Y_pred, Y_test):\n",
    "        evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "        evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "\n",
    "        evaluation_df_1['souener_pred_L2'] = evaluation_df_1['souener_pred_L1'] * evaluation_df_1['souener_pred_L1']\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1Percent'] = ((evaluation_df_1['souener'] - evaluation_df_1['souener_pred'])/evaluation_df_1['souener']) \n",
    "\n",
    "        TotalAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()\n",
    "\n",
    "        TotalSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()\n",
    "\n",
    "        MeanAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()/evaluation_df_1['souener_pred_L1'].abs().count()\n",
    "\n",
    "        MeanSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()/evaluation_df_1['souener_pred_L2'].abs().count()\n",
    "\n",
    "        NumPoints = evaluation_df_1['souener_pred_L1Percent'].abs().count()\n",
    "\n",
    "        MeanPercentageError = evaluation_df_1['souener_pred_L1Percent'].abs().sum()/NumPoints\n",
    "\n",
    "        return [TotalAbsoluteError,TotalSquaredError,MeanAbsoluteError,MeanSquaredError,MeanPercentageError,NumPoints]\n",
    "\n",
    "            \n",
    "    def printError (self,err):\n",
    "        TotalAbsoluteError = err[0]\n",
    "\n",
    "        TotalSquaredError = err[1]\n",
    "\n",
    "        MeanAbsoluteError = err[2]\n",
    "\n",
    "        MeanSquaredError = err[3]\n",
    "\n",
    "        MeanPercentageError = err[4]\n",
    "\n",
    "        NumPoints = err[5]\n",
    "        \n",
    "        print ('Total Absolute Error: ', TotalAbsoluteError)\n",
    "        print ('Mean Absolute Error: ', MeanAbsoluteError)\n",
    "        print ('Mean Percentage Error: ', MeanPercentageError)\n",
    "        print ('Total Squared Error: ', TotalSquaredError)\n",
    "        print ('Mean Squared Error: ', MeanSquaredError)\n",
    "        print ('Number of Points: ', NumPoints)\n",
    "\n",
    "    def computeAndPrintError(self,Y_pred, Y_test):    \n",
    "        self.err = computeError (Y_pred, Y_test)\n",
    "        printError (err)\n",
    "        logError(err)\n",
    "        return err    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitModelAndCalcErr(self,X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "        fit_times = []\n",
    "        \n",
    "        pred_times = []\n",
    "        \n",
    "        errs = []\n",
    "        \n",
    "        for itr in range(1,11):\n",
    "            \n",
    "            t = time.process_time()\n",
    "\n",
    "            self.model.fit(X_train, {\"prediction\":Y_train},validation_split=0.2,verbose=0,epochs=100)\n",
    "\n",
    "            fit_times.append(time.process_time() - t)\n",
    "        \n",
    "            t = time.process_time()\n",
    "\n",
    "            Y_pred = self.model.predict(X_test)\n",
    "            \n",
    "            #sns.residplot(Y_pred.flatten(), getResiduals(Y_test,Y_pred))\n",
    "\n",
    "            pred_times.append(time.process_time() - t)\n",
    "            \n",
    "            errs.append(self.computeError (Y_pred, Y_test))\n",
    "        \n",
    "        self.fit_time = sum(fit_times)/len(fit_times)\n",
    "        \n",
    "        self.pred_time = sum(pred_times)/len(pred_times)\n",
    "        \n",
    "        #computeAndPrintError(Y_pred, Y_test)\n",
    "\n",
    "        self.df_err = pd.DataFrame(errs, columns = ['TAE', 'TSE', 'MAE', 'MSE', 'MAPE', '#Pts'])\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = DNNExperimentExecutor()\\n\\nexpExectr.executeExperiments(dm, \"Simple_DNN\", df_dnnexperimentTracker)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = DNNExperimentExecutor()\n",
    "\n",
    "expExectr.executeExperiments(dm, \"Simple_DNN\", df_dnnexperimentTracker)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dnnexperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_dnnexperimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments_SimpleDNN.csv', sep='\\t',encoding='utf-8', index=False)\\n\\n#!!!!!!! Very Important !!!!!!\\nresultsFile.close()\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_dnnexperimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments_SimpleDNN.csv', sep='\\t',encoding='utf-8', index=False)\n",
    "\n",
    "#!!!!!!! Very Important !!!!!!\n",
    "resultsFile.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCDNN Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDNNExperimentExecutor:\n",
    "    def __init__(self):\n",
    "        self.dm = None\n",
    "        self.modelType = None\n",
    "        self.model = None\n",
    "        self.df_experimentTracker = None\n",
    "        self.fit_time = None\n",
    "        self.pred_time = None\n",
    "        self.err = None\n",
    "        self.df_err = None \n",
    "        self.width = 512\n",
    "        self.halfwidth = 128 \n",
    "        self.predicitions = None\n",
    "    \n",
    "    def setModel(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def getPredicitons(self):\n",
    "        return self.predicitions\n",
    "\n",
    "    def build_and_compile_pcdnn_v1_wo_zmix_model(self,noOfInputNeurons,noOfCpv):\n",
    "\n",
    "        species_inputs = keras.Input(shape=(noOfInputNeurons,), name=\"species_input\")\n",
    "\n",
    "        linear_reduced_dims = layers.Dense(noOfCpv, name=\"linear_layer\")(species_inputs)\n",
    "\n",
    "        x = layers.Dense(32, activation=\"relu\")(linear_reduced_dims)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        #Predict the source energy\n",
    "        souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "        physics_pred = layers.Dense(noOfCpv, name=\"physics\")(linear_reduced_dims)\n",
    "        \n",
    "        model = keras.Model(inputs=[species_inputs],outputs=[souener_pred,physics_pred])\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(loss={\"physics\": keras.losses.MeanAbsoluteError(),\"prediction\": keras.losses.MeanAbsoluteError()},loss_weights=[2.0, 0.2],optimizer=opt)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def build_and_compile_pcdnn_v1_with_zmix_model(self,noOfInputNeurons,noOfCpv):\n",
    "\n",
    "        species_inputs = keras.Input(shape=(noOfInputNeurons,), name=\"species_input\")\n",
    "        \n",
    "        linear_reduced_dims = layers.Dense(noOfCpv, name=\"linear_layer\")(species_inputs)\n",
    "\n",
    "        zmix = keras.Input(shape=(1,), name=\"zmix\")\n",
    "            \n",
    "        x = layers.concatenate([linear_reduced_dims,zmix])\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        #Predict the source energy\n",
    "        souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "        physics_pred = layers.Dense(noOfCpv, name=\"physics\")(linear_reduced_dims)\n",
    "        \n",
    "        model = keras.Model(inputs=[species_inputs,zmix],outputs=[souener_pred,physics_pred])\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(loss={\"physics\": keras.losses.MeanAbsoluteError(),\"prediction\": keras.losses.MeanAbsoluteError()},loss_weights=[2.0, 0.2],optimizer=opt)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def executeExperiment(self,dataManager, modelType, dataType=\"randomequaltraintestsplit\",inputType=\"ZmixPCA\",noOfCpv=5):\n",
    "        self.dm = dataManager\n",
    "        \n",
    "        self.modelType = modelType\n",
    "        \n",
    "        dataSetMethod = inputType + '_' + dataType\n",
    "        \n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, None)\n",
    "        \n",
    "        #(self,X_train, Y_train, X_test, Y_test, rom_train = None, rom_test = None, zmix_train = None, zmix_test = None, Y_scaler = None)\n",
    "        self.fitModelAndCalcErr(self.dm.X_train, self.dm.Y_train, self.dm.X_test, self.dm.Y_test,self.dm.rom_train, self.dm.rom_test, self.dm.zmix_train, self.dm.zmix_test, self.dm.outputScaler)\n",
    "        \n",
    "        if inputType.find('Zmix') != -1:\n",
    "            ZmixPresent = 'Y'\n",
    "        else:\n",
    "            ZmixPresent = 'N'\n",
    "\n",
    "                            #['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.df_err['MAE'].mean()),str(self.df_err['TAE'].mean()),str(self.df_err['MSE'].mean()),str(self.df_err['TSE'].mean()),str(self.df_err['#Pts'].mean()),str(self.fit_time),str(self.pred_time),str(self.df_err['MAE'].max()),str(self.df_err['TAE'].max()),str(self.df_err['MSE'].max()),str(self.df_err['TSE'].max()),str(self.df_err['MAE'].min()),str(self.df_err['TAE'].min()),str(self.df_err['MSE'].min()),str(self.df_err['TSE'].min())]\n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.err[2])\n",
    "\n",
    "        print(printStr)\n",
    "    \n",
    "    def executeSingleExperiment(self,noOfInputNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv,concatenateZmix):\n",
    "        \n",
    "        \n",
    "        #                           dataSetMethod,noOfCpvs, ipscaler, opscaler\n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, None, \"MinMaxScaler\")\n",
    "        \n",
    "        if concatenateZmix == 'N':\n",
    "            print(\"--------------------self.build_and_compile_pcdnn_v1_wo_zmix_model----------------------\")\n",
    "            self.model = self.build_and_compile_pcdnn_v1_wo_zmix_model(noOfInputNeurons,noOfCpv)\n",
    "            \n",
    "        else:\n",
    "            self.model = self.build_and_compile_pcdnn_v1_with_zmix_model(noOfInputNeurons,noOfCpv)\n",
    "\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "        #(self,X_train, Y_train, X_test, Y_test, rom_train = None, rom_test = None, zmix_train = None, zmix_test = None, Y_scaler = None)\n",
    "        if self.dm.inputScaler is not None:\n",
    "            X_train = self.dm.X_scaled_train\n",
    "            X_test = self.dm.X_scaled_test\n",
    "            zmix_train = self.dm.zmix_scaled_train\n",
    "            zmix_test = self.dm.zmix_scaled_test\n",
    "        else:\n",
    "            X_train = self.dm.X_train\n",
    "            X_test = self.dm.X_test\n",
    "            zmix_train = self.dm.zmix_train\n",
    "            zmix_test = self.dm.zmix_test\n",
    "        \n",
    "        if self.dm.outputScaler is not None:\n",
    "            Y_train = self.dm.Y_scaled_train\n",
    "            Y_test = self.dm.Y_scaled_test\n",
    "            rom_train = self.dm.rom_scaled_train\n",
    "            rom_test = self.dm.rom_scaled_test\n",
    "        else:\n",
    "            Y_train = self.dm.Y_train\n",
    "            Y_test = self.dm.Y_test\n",
    "            rom_train = self.dm.rom_train\n",
    "            rom_test = self.dm.rom_test\n",
    "            \n",
    "        self.fitModelAndCalcErr(X_train, Y_train, X_test, Y_test,rom_train, rom_test, zmix_train, zmix_test, self.dm.outputScaler, concatenateZmix)\n",
    "\n",
    "        #['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,str(self.df_err['MAE'].mean()),str(self.df_err['TAE'].mean()),str(self.df_err['MSE'].mean()),str(self.df_err['TSE'].mean()),str(self.df_err['#Pts'].mean()),str(self.fit_time),str(self.pred_time),str(self.df_err['MAE'].max()),str(self.df_err['TAE'].max()),str(self.df_err['MSE'].max()),str(self.df_err['TSE'].max()),str(self.df_err['MAE'].min()),str(self.df_err['TAE'].min()),str(self.df_err['MSE'].min()),str(self.df_err['TSE'].min())]\n",
    "\n",
    "        self.df_experimentTracker.loc[len(self.df_experimentTracker)] = experimentResults        \n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.df_err['MAE'].min())\n",
    "\n",
    "        print(printStr)\n",
    "\n",
    "        printStr = \"\\t\"\n",
    "\n",
    "        printStr = printStr.join(experimentResults)\n",
    "\n",
    "        resultsFile.write(printStr)\n",
    "\n",
    "        resultsFile.write(\"\\n\")\n",
    "\n",
    "\n",
    "    def fitModelAndCalcErr(self,X_train, Y_train, X_test, Y_test, rom_train = None, rom_test = None, zmix_train = None, zmix_test = None, Y_scaler = None, concatenateZmix = 'N'):\n",
    "\n",
    "        fit_times = []\n",
    "        \n",
    "        pred_times = []\n",
    "        \n",
    "        errs = []\n",
    "        \n",
    "        for itr in range(1,11):\n",
    "            \n",
    "            t = time.process_time()\n",
    "\n",
    "            if concatenateZmix == 'Y':\n",
    "                history = self.model.fit({\"species_input\":X_train, \"zmix\":zmix_train}, {\"physics\":rom_train,\"prediction\":Y_train},validation_split=0.2,verbose=0,epochs=100)\n",
    "            else:\n",
    "                history = self.model.fit({\"species_input\":X_train}, {\"physics\":rom_train,\"prediction\":Y_train},validation_split=0.2,verbose=0,epochs=100)\n",
    "            \n",
    "            #self.plot_loss_physics_and_regression(history)\n",
    "            \n",
    "            fit_times.append(time.process_time() - t)\n",
    "        \n",
    "            t = time.process_time()\n",
    "\n",
    "            if concatenateZmix == 'Y':\n",
    "                predictions = self.model.predict({\"species_input\":X_test, \"zmix\":zmix_test})\n",
    "            else:\n",
    "                predictions = self.model.predict({\"species_input\":X_test})\n",
    "                \n",
    "            pred_times.append(time.process_time() - t)\n",
    "            \n",
    "            self.predicitions = predictions\n",
    "            \n",
    "            Y_pred = predictions[0]\n",
    "            \n",
    "\n",
    "            if Y_scaler is not None:\n",
    "                Y_pred = Y_scaler.inverse_transform(Y_pred)\n",
    "                \n",
    "                \n",
    "            #sns.residplot(Y_pred.flatten(), getResiduals(Y_test,Y_pred))\n",
    "\n",
    "            errs.append(self.computeError (Y_pred, Y_test))\n",
    "        \n",
    "        self.fit_time = sum(fit_times)/len(fit_times)\n",
    "        \n",
    "        self.pred_time = sum(pred_times)/len(pred_times)\n",
    "        \n",
    "        #computeAndPrintError(Y_pred, Y_test)\n",
    "\n",
    "        self.df_err = pd.DataFrame(errs, columns = ['TAE', 'TSE', 'MAE', 'MSE', 'MAPE', '#Pts'])\n",
    "        \n",
    "        return  \n",
    "\n",
    "    def executeExperiments(self,dataManager, modelType, df_experimentTracker):\n",
    "        self.dm = dataManager\n",
    "        self.modelType = modelType\n",
    "        self.df_experimentTracker = df_experimentTracker\n",
    "        \n",
    "        #Experiments  \n",
    "        \n",
    "        #dataTypes = [\"randomequaltraintestsplit\",\"frameworkincludedtrainexcludedtest\"]\n",
    "        dataTypes = [\"frameworkincludedtrainexcludedtest\"]\n",
    "        #dataTypes = [\"randomequaltraintestsplit\"]\n",
    "        \n",
    "        inputTypes = [\"AllSpeciesZmixCpv\",\"AllSpeciesZmixPCA\",\"AllSpeciesPurePCA\",\"AllSpeciesSparsePCA\",\"AllSpeciesZmixAndPurePCA\",\"AllSpeciesZmixAndSparsePCA\"]\n",
    "        \n",
    "        #inputTypes = [\"AllSpeciesZmixAndPurePCA\"]\n",
    "        \n",
    "        concatenateZmix = 'N'\n",
    "        \n",
    "        for dataType in dataTypes:\n",
    "            print('=================== ' + dataType + ' ===================')\n",
    "            \n",
    "            for inputType in inputTypes:\n",
    "                \n",
    "                print('------------------ ' + inputType + ' ------------------')\n",
    "                    \n",
    "                #ZmixCpv_randomequaltraintestsplit\n",
    "                dataSetMethod = inputType + '_' + dataType\n",
    "                \n",
    "                noOfNeurons = 53\n",
    "\n",
    "                #ZmixAnd & ZmixAll\n",
    "                if inputType.find('ZmixA') != -1:\n",
    "                    concatenateZmix = 'Y'\n",
    "                else:\n",
    "                    concatenateZmix = 'N'\n",
    "\n",
    "                if inputType.find('Zmix') != -1:\n",
    "                    ZmixPresent = 'Y'\n",
    "                else:\n",
    "                    ZmixPresent = 'N'\n",
    "                    \n",
    "                \n",
    "                if inputType.find('PCA') != -1:\n",
    "                    \n",
    "                    noOfCpvs = [item for item in range(1, 6)]\n",
    "                    \n",
    "                    for noOfCpv in noOfCpvs:\n",
    "                        \n",
    "                        self.executeSingleExperiment(noOfNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv,concatenateZmix)\n",
    "                else:\n",
    "\n",
    "                    if inputType.find('ZmixCpv') != -1:\n",
    "                        noOfCpv = 1\n",
    "                 \n",
    "                    else:\n",
    "                        noOfCpv = 53\n",
    "                 \n",
    "                    print('------------------ ' + str(noOfNeurons) + ' ------------------')\n",
    "                    self.executeSingleExperiment(noOfNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv,concatenateZmix)\n",
    "        \n",
    "    def computeError (self,Y_pred, Y_test):\n",
    "        evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "        evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "\n",
    "        evaluation_df_1['souener_pred_L2'] = evaluation_df_1['souener_pred_L1'] * evaluation_df_1['souener_pred_L1']\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1Percent'] = ((evaluation_df_1['souener'] - evaluation_df_1['souener_pred'])/evaluation_df_1['souener']) \n",
    "\n",
    "        TotalAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()\n",
    "\n",
    "        TotalSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()\n",
    "\n",
    "        MeanAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()/evaluation_df_1['souener_pred_L1'].abs().count()\n",
    "\n",
    "        MeanSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()/evaluation_df_1['souener_pred_L2'].abs().count()\n",
    "\n",
    "        NumPoints = evaluation_df_1['souener_pred_L1Percent'].abs().count()\n",
    "\n",
    "        MeanPercentageError = evaluation_df_1['souener_pred_L1Percent'].abs().sum()/NumPoints\n",
    "\n",
    "        return [TotalAbsoluteError,TotalSquaredError,MeanAbsoluteError,MeanSquaredError,MeanPercentageError,NumPoints]\n",
    "\n",
    "            \n",
    "    def printError (self,err):\n",
    "        TotalAbsoluteError = err[0]\n",
    "\n",
    "        TotalSquaredError = err[1]\n",
    "\n",
    "        MeanAbsoluteError = err[2]\n",
    "\n",
    "        MeanSquaredError = err[3]\n",
    "\n",
    "        MeanPercentageError = err[4]\n",
    "\n",
    "        NumPoints = err[5]\n",
    "        \n",
    "        print ('Total Absolute Error: ', TotalAbsoluteError)\n",
    "        print ('Mean Absolute Error: ', MeanAbsoluteError)\n",
    "        print ('Mean Percentage Error: ', MeanPercentageError)\n",
    "        print ('Total Squared Error: ', TotalSquaredError)\n",
    "        print ('Mean Squared Error: ', MeanSquaredError)\n",
    "        print ('Number of Points: ', NumPoints)\n",
    "\n",
    "    def computeAndPrintError(self,Y_pred, Y_test):    \n",
    "        self.err = computeError (Y_pred, Y_test)\n",
    "        printError (err)\n",
    "        logError(err)\n",
    "        return err    \n",
    "        \n",
    "    def plot_loss_physics_and_regression(self,history):\n",
    "        \n",
    "        f = plt.figure(figsize=(10,3))\n",
    "        ax = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "\n",
    "        ax.plot(history.history['prediction_loss'], label='loss')\n",
    "        ax.plot(history.history['val_prediction_loss'], label='val_loss')\n",
    "        ax.set_title('Souener Prediction Loss')\n",
    "        ax.set(xlabel='Epoch', ylabel='Souener Error')\n",
    "        ax.legend()\n",
    "\n",
    "        ax2.plot(history.history['physics_loss'], label='loss')\n",
    "        ax2.plot(history.history['val_physics_loss'], label='val_loss')\n",
    "        ax2.set_title('Physics Loss')\n",
    "        ax2.set(xlabel='Epoch', ylabel='Physics Error')\n",
    "        ax2.legend()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndnnexperimentTrackingFields = [\\'Model\\',\\'Dataset\\',\\'Cpv Type\\',\\'#Cpv\\',\"ZmixExists\",\\'MAE\\',\\'TAE\\',\\'MSE\\',\\'TSE\\',\\'#Pts\\',\\'FitTime\\',\\'PredTime\\',\\'MAX-MAE\\',\\'MAX-TAE\\',\\'MAX-MSE\\',\\'MAX-TSE\\',\\'MIN-MAE\\',\\'MIN-TAE\\',\\'MIN-MSE\\',\\'MIN-TSE\\']\\n\\ndf_pcdnnexperimentTracker = pd.DataFrame(columns=dnnexperimentTrackingFields)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dnnexperimentTrackingFields = ['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "df_pcdnnexperimentTracker = pd.DataFrame(columns=dnnexperimentTrackingFields)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os#must import this library\\n\\nif os.path.exists(\\'results.csv\\'):\\n        os.remove(\\'results.csv\\') #this deletes the file\\nelse:\\n        print(\"The results.csv file does not exist\")\\n\\nresultsFile = open(\\'results.csv\\', \\'w\\')\\n\\nprintStr = \"\\t\"\\n\\nprintStr = printStr.join(dnnexperimentTrackingFields)\\n\\n\\nresultsFile.write(printStr)\\n\\nresultsFile.write(\"\\n\")\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os#must import this library\n",
    "\n",
    "if os.path.exists('results.csv'):\n",
    "        os.remove('results.csv') #this deletes the file\n",
    "else:\n",
    "        print(\"The results.csv file does not exist\")\n",
    "\n",
    "resultsFile = open('results.csv', 'w')\n",
    "\n",
    "printStr = \"\\t\"\n",
    "\n",
    "printStr = printStr.join(dnnexperimentTrackingFields)\n",
    "\n",
    "\n",
    "resultsFile.write(printStr)\n",
    "\n",
    "resultsFile.write(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexpExectr = PCDNNExperimentExecutor()\\n\\nexpExectr.executeExperiments(dm, \"PCDNN\", df_pcdnnexperimentTracker)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "expExectr = PCDNNExperimentExecutor()\n",
    "\n",
    "expExectr.executeExperiments(dm, \"PCDNN\", df_pcdnnexperimentTracker)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_pcdnnexperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_pcdnnexperimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments_PCDNN.csv', sep='\\t',encoding='utf-8', index=False)\\n\\n#!!!!!!! Very Important !!!!!!\\nresultsFile.close()\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_pcdnnexperimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments_PCDNN.csv', sep='\\t',encoding='utf-8', index=False)\n",
    "\n",
    "#!!!!!!! Very Important !!!!!!\n",
    "resultsFile.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCDNN V2 Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers, activations, initializers, constraints, Sequential\n",
    "from tensorflow.keras.constraints import UnitNorm, Constraint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class WeightsOrthogonalityConstraint (Constraint):\n",
    "    def __init__(self, encoding_dim, weightage = 1.0, axis = 0):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.weightage = weightage\n",
    "        self.axis = axis\n",
    "        \n",
    "    def weights_orthogonality(self, w):\n",
    "        if(self.axis==1):\n",
    "            w = tf.transpose(w)\n",
    "        if(self.encoding_dim > 1):\n",
    "            m = tf.matmul(tf.transpose(w), w) - tf.eye(self.encoding_dim)\n",
    "            return self.weightage * tf.math.sqrt(tf.math.reduce_sum(tf.math.square(m)))\n",
    "        else:\n",
    "            m = tf.math.reduce_sum(w ** 2) - 1.\n",
    "            return m\n",
    "\n",
    "    def __call__(self, w):\n",
    "        return self.weights_orthogonality(w)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'encoding_dim':encoding_dim}\n",
    "    \n",
    "\n",
    "class UncorrelatedFeaturesConstraint (Constraint):\n",
    "\n",
    "    def __init__(self, encoding_dim, weightage=1.0):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.weightage = weightage\n",
    "\n",
    "    def get_covariance(self, x):\n",
    "        x_centered_list = []\n",
    "\n",
    "        for i in range(self.encoding_dim):\n",
    "            x_centered_list.append(x[:, i] - tf.math.reduce_mean(x[:, i]))\n",
    "\n",
    "        x_centered = tf.stack(x_centered_list)\n",
    "        covariance = tf.matmul(x_centered, tf.transpose(x_centered)) / \\\n",
    "            tf.cast(x_centered.get_shape()[0], tf.float32)\n",
    "\n",
    "        return covariance\n",
    "\n",
    "    # Constraint penalty\n",
    "    def uncorrelated_feature(self, x):\n",
    "        if(self.encoding_dim <= 1):\n",
    "            return 0.0\n",
    "        else:\n",
    "            output = tf.math.reduce_sum(tf.math.square(\n",
    "                self.covariance - tf.math.multiply(self.covariance, tf.eye(self.encoding_dim))))\n",
    "            return output\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.covariance = self.get_covariance(x)\n",
    "        return self.weightage * self.uncorrelated_feature(x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'weightage': self.weightage, 'encoding_dim':encoding_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCDNNV2ExperimentExecutor:\n",
    "    def __init__(self):\n",
    "        self.dm = None\n",
    "        self.modelType = None\n",
    "        self.model = None\n",
    "        self.df_experimentTracker = None\n",
    "        self.fit_time = None\n",
    "        self.pred_time = None\n",
    "        self.err = None\n",
    "        self.df_err = None \n",
    "        self.width = 512\n",
    "        self.halfwidth = 128 \n",
    "        self.predicitions = None\n",
    "    \n",
    "    def setModel(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def getPredicitons(self):\n",
    "        return self.predicitions\n",
    "\n",
    "    def build_and_compile_pcdnn_v1_wo_zmix_model(self,noOfInputNeurons,noOfCpv,kernel_constraint='Y',kernel_regularizer='Y',activity_regularizer='Y'):\n",
    "\n",
    "        print (noOfInputNeurons,noOfCpv,kernel_constraint,kernel_regularizer,activity_regularizer)\n",
    "        \n",
    "        species_inputs = keras.Input(shape=(noOfInputNeurons,), name=\"species_input\")\n",
    "        \n",
    "        x = self.getLinearLayer(noOfInputNeurons,noOfCpv,kernel_constraint,kernel_regularizer,activity_regularizer)(species_inputs)\n",
    "        \n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        #Predict the source energy\n",
    "        souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=[species_inputs],outputs=[souener_pred],)\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(loss='mean_absolute_error',optimizer=opt)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    \n",
    "    def getLinearLayer(self,noOfInputNeurons,noOfCpv,kernel_constraint='Y',kernel_regularizer='Y',activity_regularizer='Y'):\n",
    "        \n",
    "        if kernel_constraint=='Y'and kernel_regularizer =='N' and activity_regularizer =='N':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_constraint=UnitNorm(axis=0))\n",
    "        \n",
    "        elif kernel_constraint=='N'and kernel_regularizer =='Y' and activity_regularizer =='N':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_regularizer=WeightsOrthogonalityConstraint(noOfCpv, weightage=1., axis=0))\n",
    "            \n",
    "        elif kernel_constraint=='N'and kernel_regularizer =='N' and activity_regularizer =='Y':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",activity_regularizer=UncorrelatedFeaturesConstraint(noOfCpv, weightage=1.))\n",
    "        \n",
    "        elif kernel_constraint=='Y'and kernel_regularizer =='Y' and activity_regularizer =='N':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_constraint=UnitNorm(axis=0),kernel_regularizer=WeightsOrthogonalityConstraint(noOfCpv, weightage=1., axis=0))\n",
    "        \n",
    "        elif kernel_constraint=='Y'and kernel_regularizer =='N' and activity_regularizer =='Y':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_constraint=UnitNorm(axis=0),activity_regularizer=UncorrelatedFeaturesConstraint(noOfCpv, weightage=1.))\n",
    "        \n",
    "        elif kernel_constraint=='N'and kernel_regularizer =='Y' and activity_regularizer =='Y':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_regularizer=WeightsOrthogonalityConstraint(noOfCpv, weightage=1., axis=0),activity_regularizer=UncorrelatedFeaturesConstraint(noOfCpv, weightage=1.))\n",
    "        \n",
    "        elif kernel_constraint=='N'and kernel_regularizer =='N' and activity_regularizer =='N':\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\")\n",
    "                \n",
    "        else:\n",
    "            layer = layers.Dense(noOfCpv, activation=\"linear\",kernel_constraint=UnitNorm(axis=0),kernel_regularizer=WeightsOrthogonalityConstraint(noOfCpv, weightage=1., axis=0),activity_regularizer=UncorrelatedFeaturesConstraint(noOfCpv, weightage=1.))\n",
    "        return layer\n",
    "\n",
    "    def build_and_compile_pcdnn_v1_with_zmix_model(self,noOfInputNeurons,noOfCpv,kernel_constraint='Y',kernel_regularizer='Y',activity_regularizer='Y'):\n",
    "\n",
    "        species_inputs = keras.Input(shape=(noOfInputNeurons,), name=\"species_input\")\n",
    "\n",
    "        Zmix = keras.Input(shape=(1,), name=\"Zmix\")\n",
    "\n",
    "        x = self.getLinearLayer(noOfInputNeurons,noOfCpv,kernel_constraint,kernel_regularizer,activity_regularizer)(species_inputs)\n",
    "\n",
    "        #Concatenate the Linear Embedding and Zmix together\n",
    "        x = layers.Concatenate()([Zmix, x])\n",
    "\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(512, activation=\"relu\")(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = layers.Dense(64, activation=\"relu\")(x)\n",
    "        x = layers.Dense(32, activation=\"relu\")(x)\n",
    "        #Predict the source energy\n",
    "        souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=[species_inputs,Zmix],outputs=[souener_pred],)\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        model.compile(loss='mean_absolute_error',optimizer=opt)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def executeSingleExperiment(self,noOfInputNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv,concatenateZmix,kernel_constraint,kernel_regularizer,activity_regularizer):\n",
    "        \n",
    "        \n",
    "        #                           dataSetMethod,noOfCpvs, ipscaler, opscaler\n",
    "        self.dm.createTrainTestData(dataSetMethod,noOfCpv, \"MinMaxScaler\", \"MinMaxScaler\")\n",
    "        \n",
    "        if concatenateZmix == 'N':\n",
    "            print(\"--------------------self.build_and_compile_pcdnn_v1_wo_zmix_model----------------------\")\n",
    "            self.model = self.build_and_compile_pcdnn_v1_wo_zmix_model(noOfInputNeurons,noOfCpv,kernel_constraint,kernel_regularizer,activity_regularizer)\n",
    "            \n",
    "        else:\n",
    "            self.model = self.build_and_compile_pcdnn_v1_with_zmix_model(noOfInputNeurons,noOfCpv,kernel_constraint,kernel_regularizer,activity_regularizer)\n",
    "\n",
    "        \n",
    "        self.model.summary()\n",
    "\n",
    "        #(self,X_train, Y_train, X_test, Y_test, rom_train = None, rom_test = None, zmix_train = None, zmix_test = None, Y_scaler = None)\n",
    "        if self.dm.inputScaler is not None:\n",
    "            X_train = self.dm.X_scaled_train\n",
    "            X_test = self.dm.X_scaled_test\n",
    "            zmix_train = self.dm.zmix_scaled_train\n",
    "            zmix_test = self.dm.zmix_scaled_test\n",
    "        else:\n",
    "            X_train = self.dm.X_train\n",
    "            X_test = self.dm.X_test\n",
    "            zmix_train = self.dm.zmix_train\n",
    "            zmix_test = self.dm.zmix_test\n",
    "        \n",
    "        if self.dm.outputScaler is not None:\n",
    "            Y_train = self.dm.Y_scaled_train\n",
    "            Y_test = self.dm.Y_scaled_test\n",
    "        else:\n",
    "            Y_train = self.dm.Y_train\n",
    "            Y_test = self.dm.Y_test\n",
    "\n",
    "            \n",
    "        self.fitModelAndCalcErr(X_train, Y_train, X_test, Y_test,None, None, zmix_train, zmix_test, self.dm.outputScaler, concatenateZmix,kernel_constraint,kernel_regularizer,activity_regularizer)\n",
    "\n",
    "        #['Model','Dataset','Cpv Type','#Cpv',\"ZmixExists\",'MAE','TAE','MSE','TSE','#Pts','FitTime','PredTime','MAX-MAE','MAX-TAE','MAX-MSE','MAX-TSE','MIN-MAE','MIN-TAE','MIN-MSE','MIN-TSE']\n",
    "\n",
    "        experimentResults = [self.modelType, dataType,inputType,str(noOfCpv), ZmixPresent,kernel_constraint,kernel_regularizer,activity_regularizer,str(self.df_err['MAE'].mean()),str(self.df_err['TAE'].mean()),str(self.df_err['MSE'].mean()),str(self.df_err['TSE'].mean()),str(self.df_err['#Pts'].mean()),str(self.fit_time),str(self.pred_time),str(self.df_err['MAE'].max()),str(self.df_err['TAE'].max()),str(self.df_err['MSE'].max()),str(self.df_err['TSE'].max()),str(self.df_err['MAE'].min()),str(self.df_err['TAE'].min()),str(self.df_err['MSE'].min()),str(self.df_err['TSE'].min())]\n",
    "\n",
    "        self.df_experimentTracker.loc[len(self.df_experimentTracker)] = experimentResults        \n",
    "\n",
    "        printStr = \"self.modelType: \"+ self.modelType+ \" dataType: \"  + dataType+ \" inputType:\"+inputType+ \" noOfCpv:\"+str(noOfCpv)+ \" ZmixPresent:\" + ZmixPresent + \" MAE:\" +str(self.df_err['MAE'].min())\n",
    "\n",
    "        print(printStr)\n",
    "\n",
    "        printStr = \"\\t\"\n",
    "\n",
    "        printStr = printStr.join(experimentResults)\n",
    "\n",
    "        resultsFile.write(printStr)\n",
    "\n",
    "        resultsFile.write(\"\\n\")\n",
    "\n",
    "\n",
    "    def fitModelAndCalcErr(self,X_train, Y_train, X_test, Y_test, rom_train = None, rom_test = None, zmix_train = None, zmix_test = None, Y_scaler = None, concatenateZmix = 'N',kernel_constraint = 'Y',kernel_regularizer = 'Y',activity_regularizer = 'Y'):\n",
    "\n",
    "        fit_times = []\n",
    "        \n",
    "        pred_times = []\n",
    "        \n",
    "        errs = []\n",
    "        \n",
    "        for itr in range(1,11):\n",
    "            \n",
    "            t = time.process_time()\n",
    "\n",
    "            if concatenateZmix == 'Y':\n",
    "                history = self.model.fit({\"species_input\":X_train, \"zmix\":zmix_train}, {\"prediction\":Y_train},validation_split=0.2,verbose=0,epochs=100)\n",
    "            else:\n",
    "                history = self.model.fit({\"species_input\":X_train}, {\"prediction\":Y_train},validation_split=0.2,verbose=0,epochs=100)\n",
    "            \n",
    "            #self.plot_loss_physics_and_regression(history)\n",
    "            \n",
    "            fit_times.append(time.process_time() - t)\n",
    "        \n",
    "            t = time.process_time()\n",
    "\n",
    "            if concatenateZmix == 'Y':\n",
    "                predictions = self.model.predict({\"species_input\":X_test, \"zmix\":zmix_test})\n",
    "            else:\n",
    "                predictions = self.model.predict({\"species_input\":X_test})\n",
    "                \n",
    "            pred_times.append(time.process_time() - t)\n",
    "            \n",
    "            self.predicitions = predictions\n",
    "            \n",
    "            Y_pred = predictions\n",
    "            \n",
    "\n",
    "            if Y_scaler is not None:\n",
    "                Y_pred = Y_scaler.inverse_transform(Y_pred)\n",
    "                \n",
    "                \n",
    "            #sns.residplot(Y_pred.flatten(), getResiduals(Y_test,Y_pred))\n",
    "\n",
    "            errs.append(self.computeError (Y_pred, Y_test))\n",
    "        \n",
    "        self.fit_time = sum(fit_times)/len(fit_times)\n",
    "        self.pred_time = sum(pred_times)/len(pred_times)\n",
    "        \n",
    "        #computeAndPrintError(Y_pred, Y_test)\n",
    "\n",
    "        self.df_err = pd.DataFrame(errs, columns = ['TAE', 'TSE', 'MAE', 'MSE', 'MAPE', '#Pts'])\n",
    "        \n",
    "        return  \n",
    "\n",
    "    def executeExperiments(self,dataManager, modelType, df_experimentTracker):\n",
    "        pdb.set_trace()\n",
    "        self.dm = dataManager\n",
    "        self.modelType = modelType\n",
    "        self.df_experimentTracker = df_experimentTracker\n",
    "        \n",
    "        #Experiments  \n",
    "        \n",
    "        #dataTypes = [\"randomequaltraintestsplit\",\"frameworkincludedtrainexcludedtest\"]\n",
    "        #dataTypes = [\"frameworkincludedtrainexcludedtest\"]\n",
    "        dataTypes = [\"randomequaltraintestsplit\"]\n",
    "        \n",
    "        #inputTypes = [\"AllSpeciesAndZmix\"]\n",
    "        \n",
    "        inputTypes = [\"AllSpecies\",\"AllSpeciesAndZmix\"]\n",
    "        \n",
    "        concatenateZmix = 'N'\n",
    "        kernel_constraints = ['Y','N']\n",
    "        kernel_regularizers = ['Y','N']\n",
    "        activity_regularizers = ['Y','N']        \n",
    "        for dataType in dataTypes:\n",
    "            print('=================== ' + dataType + ' ===================')\n",
    "            \n",
    "            for inputType in inputTypes:\n",
    "                \n",
    "                print('------------------ ' + inputType + ' ------------------')\n",
    "                    \n",
    "                #ZmixCpv_randomequaltraintestsplit\n",
    "                dataSetMethod = inputType + '_' + dataType\n",
    "                \n",
    "                noOfNeurons = 53\n",
    "\n",
    "                if inputType.find('Zmix') != -1:\n",
    "                    ZmixPresent = 'Y'\n",
    "                    concatenateZmix = 'Y'\n",
    "                else:\n",
    "                    ZmixPresent = 'N'\n",
    "                    concatenateZmix = 'N'\n",
    "                    \n",
    "                noOfCpvs = [item for item in range(2, 6)]\n",
    "\n",
    "                for noOfCpv in noOfCpvs:\n",
    "                    for kernel_constraint in kernel_constraints:\n",
    "                        for kernel_regularizer in kernel_regularizers:\n",
    "                            for activity_regularizer in activity_regularizers:\n",
    "                                 \n",
    "                                self.executeSingleExperiment(noOfNeurons,dataSetMethod,dataType,inputType,ZmixPresent,noOfCpv,concatenateZmix,kernel_constraint,kernel_regularizer,activity_regularizer)\n",
    "                       \n",
    "        \n",
    "    def computeError (self,Y_pred, Y_test):\n",
    "        evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "        evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "\n",
    "        evaluation_df_1['souener_pred_L2'] = evaluation_df_1['souener_pred_L1'] * evaluation_df_1['souener_pred_L1']\n",
    "\n",
    "        evaluation_df_1['souener_pred_L1Percent'] = ((evaluation_df_1['souener'] - evaluation_df_1['souener_pred'])/evaluation_df_1['souener']) \n",
    "\n",
    "        TotalAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()\n",
    "\n",
    "        TotalSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()\n",
    "\n",
    "        MeanAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()/evaluation_df_1['souener_pred_L1'].abs().count()\n",
    "\n",
    "        MeanSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()/evaluation_df_1['souener_pred_L2'].abs().count()\n",
    "\n",
    "        NumPoints = evaluation_df_1['souener_pred_L1Percent'].abs().count()\n",
    "\n",
    "        MeanPercentageError = evaluation_df_1['souener_pred_L1Percent'].abs().sum()/NumPoints\n",
    "\n",
    "        return [TotalAbsoluteError,TotalSquaredError,MeanAbsoluteError,MeanSquaredError,MeanPercentageError,NumPoints]\n",
    "\n",
    "            \n",
    "    def printError (self,err):\n",
    "        TotalAbsoluteError = err[0]\n",
    "\n",
    "        TotalSquaredError = err[1]\n",
    "\n",
    "        MeanAbsoluteError = err[2]\n",
    "\n",
    "        MeanSquaredError = err[3]\n",
    "\n",
    "        MeanPercentageError = err[4]\n",
    "\n",
    "        NumPoints = err[5]\n",
    "        \n",
    "        print ('Total Absolute Error: ', TotalAbsoluteError)\n",
    "        print ('Mean Absolute Error: ', MeanAbsoluteError)\n",
    "        print ('Mean Percentage Error: ', MeanPercentageError)\n",
    "        print ('Total Squared Error: ', TotalSquaredError)\n",
    "        print ('Mean Squared Error: ', MeanSquaredError)\n",
    "        print ('Number of Points: ', NumPoints)\n",
    "\n",
    "    def computeAndPrintError(self, Y_pred, Y_test):    \n",
    "        self.err = computeError (Y_pred, Y_test)\n",
    "        printError (err)\n",
    "        logError(err)\n",
    "        return err    \n",
    "        \n",
    "    def plot_loss_physics_and_regression(self,history):\n",
    "        \n",
    "        f = plt.figure(figsize=(10,3))\n",
    "        ax = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "\n",
    "        ax.plot(history.history['prediction_loss'], label='loss')\n",
    "        ax.plot(history.history['val_prediction_loss'], label='val_loss')\n",
    "        ax.set_title('Souener Prediction Loss')\n",
    "        ax.set(xlabel='Epoch', ylabel='Souener Error')\n",
    "        ax.legend()\n",
    "\n",
    "        ax2.plot(history.history['physics_loss'], label='loss')\n",
    "        ax2.plot(history.history['val_physics_loss'], label='val_loss')\n",
    "        ax2.set_title('Physics Loss')\n",
    "        ax2.set(xlabel='Epoch', ylabel='Physics Error')\n",
    "        ax2.legend()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dnnexperimentTrackingFields = ['Model', 'Dataset', 'Cpv Type', '#Cpv', \"ZmixExists\", 'KernelConstraintExists', 'KernelRegularizerExists', 'ActivityRegularizerExists', 'MAE', 'TAE', 'MSE', 'TSE', '#Pts', 'FitTime', 'PredTime', 'MAX-MAE', 'MAX-TAE', 'MAX-MSE', 'MAX-TSE', 'MIN-MAE', 'MIN-TAE', 'MIN-MSE', 'MIN-TSE']\n",
    "\n",
    "df_pcdnnexperimentTracker = pd.DataFrame(columns=dnnexperimentTrackingFields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os#must import this library\n",
    "\n",
    "if os.path.exists('results.csv'):\n",
    "        os.remove('results.csv') #this deletes the file\n",
    "else:\n",
    "        print(\"The results.csv file does not exist\")\n",
    "\n",
    "resultsFile = open('results.csv', 'w')\n",
    "\n",
    "printStr = \"\\t\"\n",
    "\n",
    "printStr = printStr.join(dnnexperimentTrackingFields)\n",
    "\n",
    "\n",
    "resultsFile.write(printStr)\n",
    "\n",
    "resultsFile.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(220)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    218 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mexecuteExperiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_experimentTracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    219 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 220 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_experimentTracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_experimentTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(221)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_experimentTracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_experimentTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(222)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_experimentTracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_experimentTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m        \u001b[0;31m#Experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(228)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    226 \u001b[0;31m        \u001b[0;31m#dataTypes = [\"randomequaltraintestsplit\",\"frameworkincludedtrainexcludedtest\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    227 \u001b[0;31m        \u001b[0;31m#dataTypes = [\"frameworkincludedtrainexcludedtest\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 228 \u001b[0;31m        \u001b[0mdataTypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"randomequaltraintestsplit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    229 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    230 \u001b[0;31m        \u001b[0;31m#inputTypes = [\"AllSpeciesAndZmix\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(232)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    230 \u001b[0;31m        \u001b[0;31m#inputTypes = [\"AllSpeciesAndZmix\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    231 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 232 \u001b[0;31m        \u001b[0minputTypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"AllSpecies\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AllSpeciesAndZmix\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    233 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    234 \u001b[0;31m        \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(234)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    232 \u001b[0;31m        \u001b[0minputTypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"AllSpecies\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AllSpeciesAndZmix\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    233 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 234 \u001b[0;31m        \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    235 \u001b[0;31m        \u001b[0mkernel_constraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    236 \u001b[0;31m        \u001b[0mkernel_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(235)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    233 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    234 \u001b[0;31m        \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 235 \u001b[0;31m        \u001b[0mkernel_constraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    236 \u001b[0;31m        \u001b[0mkernel_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    237 \u001b[0;31m        \u001b[0mactivity_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(236)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    234 \u001b[0;31m        \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    235 \u001b[0;31m        \u001b[0mkernel_constraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 236 \u001b[0;31m        \u001b[0mkernel_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    237 \u001b[0;31m        \u001b[0mactivity_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    238 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(237)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    235 \u001b[0;31m        \u001b[0mkernel_constraints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    236 \u001b[0;31m        \u001b[0mkernel_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 237 \u001b[0;31m        \u001b[0mactivity_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    238 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    239 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=================== '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ==================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(238)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    236 \u001b[0;31m        \u001b[0mkernel_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    237 \u001b[0;31m        \u001b[0mactivity_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 238 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    239 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=================== '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ==================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    240 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(239)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    237 \u001b[0;31m        \u001b[0mactivity_regularizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    238 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 239 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=================== '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ==================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    240 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    241 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> \n",
      "=================== randomequaltraintestsplit ===================\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(241)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    239 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=================== '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ==================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    240 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 241 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    242 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    243 \u001b[0;31m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------ '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(243)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    241 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputTypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    242 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 243 \u001b[0;31m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------ '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    244 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m                \u001b[0;31m#ZmixCpv_randomequaltraintestsplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "------------------ AllSpecies ------------------\n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(246)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    244 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m                \u001b[0;31m#ZmixCpv_randomequaltraintestsplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 246 \u001b[0;31m                \u001b[0mdataSetMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    247 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    248 \u001b[0;31m                \u001b[0mnoOfNeurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(248)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    246 \u001b[0;31m                \u001b[0mdataSetMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputType\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    247 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 248 \u001b[0;31m                \u001b[0mnoOfNeurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    249 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    250 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0minputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Zmix'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(250)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    248 \u001b[0;31m                \u001b[0mnoOfNeurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    249 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 250 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0minputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Zmix'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    251 \u001b[0;31m                    \u001b[0mZmixPresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    252 \u001b[0;31m                    \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(254)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    252 \u001b[0;31m                    \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    253 \u001b[0;31m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 254 \u001b[0;31m                    \u001b[0mZmixPresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    255 \u001b[0;31m                    \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(255)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    253 \u001b[0;31m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    254 \u001b[0;31m                    \u001b[0mZmixPresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 255 \u001b[0;31m                    \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    257 \u001b[0;31m                \u001b[0mnoOfCpvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(257)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    255 \u001b[0;31m                    \u001b[0mconcatenateZmix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 257 \u001b[0;31m                \u001b[0mnoOfCpvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    258 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnoOfCpv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoOfCpvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(259)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    257 \u001b[0;31m                \u001b[0mnoOfCpvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    258 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 259 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnoOfCpv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoOfCpvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    260 \u001b[0;31m                    \u001b[0;32mfor\u001b[0m \u001b[0mkernel_constraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m                        \u001b[0;32mfor\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(260)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    258 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnoOfCpv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoOfCpvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 260 \u001b[0;31m                    \u001b[0;32mfor\u001b[0m \u001b[0mkernel_constraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m                        \u001b[0;32mfor\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    262 \u001b[0;31m                            \u001b[0;32mfor\u001b[0m \u001b[0mactivity_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivity_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(261)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    259 \u001b[0;31m                \u001b[0;32mfor\u001b[0m \u001b[0mnoOfCpv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoOfCpvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    260 \u001b[0;31m                    \u001b[0;32mfor\u001b[0m \u001b[0mkernel_constraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 261 \u001b[0;31m                        \u001b[0;32mfor\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    262 \u001b[0;31m                            \u001b[0;32mfor\u001b[0m \u001b[0mactivity_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivity_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(262)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    260 \u001b[0;31m                    \u001b[0;32mfor\u001b[0m \u001b[0mkernel_constraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_constraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m                        \u001b[0;32mfor\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 262 \u001b[0;31m                            \u001b[0;32mfor\u001b[0m \u001b[0mactivity_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivity_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    264 \u001b[0;31m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuteSingleExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoOfNeurons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataSetMethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZmixPresent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoOfCpv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcatenateZmix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/var/folders/9t/_9cfpfnn1g321n6lhf7x3zqr0000gn/T/ipykernel_2270/4153706994.py\u001b[0m(264)\u001b[0;36mexecuteExperiments\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    262 \u001b[0;31m                            \u001b[0;32mfor\u001b[0m \u001b[0mactivity_regularizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivity_regularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 264 \u001b[0;31m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuteSingleExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoOfNeurons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataSetMethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZmixPresent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoOfCpv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconcatenateZmix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    265 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    266 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "In _createTrainTestData Y_test.shape: (8220, 1)\n",
      "In createTrainTestData Y_test.shape: (8220,)\n",
      "--------------------self.build_and_compile_pcdnn_v1_wo_zmix_model----------------------\n",
      "53 2 Y Y Y\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "expExectr = PCDNNV2ExperimentExecutor()\n",
    "\n",
    "expExectr.executeExperiments(dm, \"PCDNN_V2\", df_pcdnnexperimentTracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w\n",
    "df_pcdnnexperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pcdnnexperimentTracker.to_csv('PAPER1_PCA_GP_DNN_NEIGHBORDNN_PCDNN_V2_Experiments_PCDNN.csv', sep='\\t',encoding='utf-8', index=False)\n",
    "\n",
    "#!!!!!!! Very Important !!!!!!\n",
    "resultsFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Species DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_allSpecies = df[icovariates].values\n",
    "X= df[zmix_pca_dim_cols].values\n",
    "Y = df[\"souener\"].values\n",
    "from sklearn.utils import shuffle\n",
    "X_allSpecies_shuffled,X_shuffled, Y_shuffled = shuffle(X_allSpecies,X,Y, random_state=0)\n",
    "\n",
    "\n",
    "X_allSpecies_train = X_allSpecies_shuffled[::2]\n",
    "X_train = X_shuffled[::2]\n",
    "Y_train = Y_shuffled[::2]\n",
    "\n",
    "X_allSpecies_test = X_allSpecies_shuffled[1::2]\n",
    "X_test = X_shuffled[1::2]\n",
    "Y_test = Y_shuffled[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scaledusingdm = dm.Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_unscaled = dm.Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_souener = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "\n",
    "Y_unscaled = Y_unscaled.reshape(Y_unscaled.shape[0], 1)\n",
    "\n",
    "scaler_souener.fit_transform(Y_unscaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scaledusingdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create scaler\n",
    "scaler_species = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "normalized_species_train = scaler_species.fit_transform(X_allSpecies_train)\n",
    "normalized_species_test = scaler_species.fit_transform(X_allSpecies_test)\n",
    "\n",
    "# create scaler\n",
    "scaler_zmixpca = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "normalized_zmixpca_train = scaler_zmixpca.fit_transform(X_train)\n",
    "normalized_zmixpca_test = scaler_zmixpca.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "scaler_souener = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "normalized_souener_train = scaler_souener.fit_transform(Y_train)\n",
    "normalized_souener_test = scaler_souener.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_souener_train = normalized_souener_train.flatten()\n",
    "normalized_souener_test = normalized_souener_test.flatten()\n",
    "\n",
    "Y_train = Y_train.flatten()\n",
    "Y_test = Y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_souener_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "species_inputs = keras.Input(shape=(53,), name=\"species_input\")\n",
    "\n",
    "linear_reduced_dims = layers.Dense(5, name=\"linear_layer\")(species_inputs)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(linear_reduced_dims)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "#Predict the source energy\n",
    "souener_pred = layers.Dense(1, name=\"prediction\")(x)\n",
    "\n",
    "physics_pred = layers.Dense(5, name=\"physics\")(linear_reduced_dims)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[species_inputs],\n",
    "    outputs=[souener_pred, physics_pred],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss={\n",
    "        \"physics\": keras.losses.MeanAbsoluteError(),\n",
    "        \"prediction\": keras.losses.MeanAbsoluteError(),\n",
    "    },\n",
    "    loss_weights=[2.0, 0.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dm.X_scaled_train, \n",
    "                    {\n",
    "                        \"physics\": dm.rom_scaled_train,\n",
    "                        \"prediction\":dm.Y_scaled_train\n",
    "                    },\n",
    "                    validation_split=0.2,\n",
    "                    verbose=0, \n",
    "                    epochs=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#batch_size=100,\n",
    "history = model.fit(normalized_species_train, \n",
    "                    {\n",
    "                        \"physics\": normalized_zmixpca_train,\n",
    "                        \"prediction\":normalized_souener_train#Y_train\n",
    "                    },\n",
    "                    validation_split=0.2,\n",
    "                    verbose=0, \n",
    "                    epochs=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_physics_and_regression(history):\n",
    "        \n",
    "    f = plt.figure(figsize=(10,3))\n",
    "    ax = f.add_subplot(121)\n",
    "    ax2 = f.add_subplot(122)\n",
    "    \n",
    "    ax.plot(history.history['prediction_loss'], label='loss')\n",
    "    ax.plot(history.history['val_prediction_loss'], label='val_loss')\n",
    "    ax.set_title('Souener Prediction Loss')\n",
    "    ax.set(xlabel='Epoch', ylabel='Souener Error')\n",
    "    ax.legend()\n",
    "\n",
    "    ax2.plot(history.history['physics_loss'], label='loss')\n",
    "    ax2.plot(history.history['val_physics_loss'], label='val_loss')\n",
    "    ax2.set_title('Physics Loss')\n",
    "    ax2.set(xlabel='Epoch', ylabel='Physics Error')\n",
    "    ax2.legend()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_physics_and_regression(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_physics_and_regression(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dm.X_scaled_test)\n",
    "\n",
    "normalized_souener_pred = predictions[0]\n",
    "\n",
    "normalized_zmixpca_pred = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.createTrainTestData(\"ZmixPCA_randomequaltraintestsplit\",5, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.rom_scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dm.Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = dm.outputScaler.inverse_transform(normalized_souener_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printError (err):\n",
    "    TotalAbsoluteError = err[0]\n",
    "\n",
    "    TotalSquaredError = err[1]\n",
    "\n",
    "    MeanAbsoluteError = err[2]\n",
    "\n",
    "    MeanSquaredError = err[3]\n",
    "\n",
    "    MeanPercentageError = err[4]\n",
    "\n",
    "    NumPoints = err[5]\n",
    "\n",
    "    print ('Total Absolute Error: ', TotalAbsoluteError)\n",
    "    print ('Mean Absolute Error: ', MeanAbsoluteError)\n",
    "    print ('Mean Percentage Error: ', MeanPercentageError)\n",
    "    print ('Total Squared Error: ', TotalSquaredError)\n",
    "    print ('Mean Squared Error: ', MeanSquaredError)\n",
    "    print ('Number of Points: ', NumPoints)\n",
    "\n",
    "def computeAndPrintError(Y_pred, Y_test):    \n",
    "    printError (computeError (Y_pred, Y_test))\n",
    "    return\n",
    "\n",
    "def computeError (Y_pred, Y_test):\n",
    "    evaluation_df_1 = pd.DataFrame()\n",
    "\n",
    "    evaluation_df_1['souener'] = Y_test.flatten()\n",
    "\n",
    "    evaluation_df_1['souener_pred'] = Y_pred.flatten()\n",
    "\n",
    "    evaluation_df_1['souener_pred_L1'] = evaluation_df_1['souener'] - evaluation_df_1['souener_pred'] \n",
    "\n",
    "    evaluation_df_1['souener_pred_L2'] = evaluation_df_1['souener_pred_L1'] * evaluation_df_1['souener_pred_L1']\n",
    "\n",
    "    evaluation_df_1['souener_pred_L1Percent'] = ((evaluation_df_1['souener'] - evaluation_df_1['souener_pred'])/evaluation_df_1['souener']) \n",
    "\n",
    "    TotalAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()\n",
    "\n",
    "    TotalSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()\n",
    "\n",
    "    MeanAbsoluteError = evaluation_df_1['souener_pred_L1'].abs().sum()/evaluation_df_1['souener_pred_L1'].abs().count()\n",
    "\n",
    "    MeanSquaredError = evaluation_df_1['souener_pred_L2'].abs().sum()/evaluation_df_1['souener_pred_L2'].abs().count()\n",
    "\n",
    "    NumPoints = evaluation_df_1['souener_pred_L1Percent'].abs().count()\n",
    "\n",
    "    MeanPercentageError = evaluation_df_1['souener_pred_L1Percent'].abs().sum()/NumPoints\n",
    "\n",
    "    return [TotalAbsoluteError,TotalSquaredError,MeanAbsoluteError,MeanSquaredError,MeanPercentageError,NumPoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = computeAndPrintError(Y_pred, dm.Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.residplot(dm.Y_test, getResiduals(dm.Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(normalized_species_test)\n",
    "\n",
    "normalized_souener_pred = predictions[0]\n",
    "\n",
    "normalized_zmixpca_pred = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = scaler_souener.inverse_transform(normalized_souener_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = computeAndPrintError(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(Y_test.flatten(), getResiduals(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total Absolute Error:  6563454066133.884\n",
    "Mean Absolute Error:  798570880.4153649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total Absolute Error:  4075696778120.0723\n",
    "Mean Absolute Error:  495887185.56029594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pcdnn_paper_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
